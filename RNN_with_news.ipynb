{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPw_A2ta3vim"
   },
   "source": [
    "# Chargement des données déjà préparées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les news sont les 10000 derniers fichiers de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vZTDQYA73vim"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s_g3WVMx3viq"
   },
   "outputs": [],
   "source": [
    "def load(list_files):\n",
    "    list_files = np.sort(list_files)\n",
    "    res = []\n",
    "    for i in range(list_files.shape[0]):\n",
    "        if i%100==0 and i > 0:\n",
    "            print(\"i=\", i)\n",
    "        res.append(sparse.load_npz(file=list_files[i]))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "directory = \"texts_matrices_with_news\"\n",
    "directory2 = \"size_texts_with_news\"\n",
    "directory3 = \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n",
      "i= 6600\n",
      "i= 6700\n",
      "i= 6800\n",
      "i= 6900\n",
      "i= 7000\n",
      "i= 7100\n",
      "i= 7200\n",
      "i= 7300\n",
      "i= 7400\n",
      "i= 7500\n",
      "i= 7600\n",
      "i= 7700\n",
      "i= 7800\n",
      "i= 7900\n",
      "i= 8000\n",
      "i= 8100\n",
      "i= 8200\n",
      "i= 8300\n",
      "i= 8400\n",
      "i= 8500\n",
      "i= 8600\n",
      "i= 8700\n",
      "i= 8800\n",
      "i= 8900\n",
      "i= 9000\n",
      "i= 9100\n",
      "i= 9200\n",
      "i= 9300\n",
      "i= 9400\n",
      "i= 9500\n",
      "i= 9600\n",
      "i= 9700\n",
      "i= 9800\n",
      "i= 9900\n",
      "i= 10000\n",
      "i= 10100\n",
      "i= 10200\n",
      "i= 10300\n",
      "i= 10400\n",
      "i= 10500\n",
      "i= 10600\n",
      "i= 10700\n",
      "i= 10800\n",
      "i= 10900\n",
      "i= 11000\n",
      "i= 11100\n",
      "i= 11200\n",
      "i= 11300\n",
      "i= 11400\n",
      "i= 11500\n",
      "i= 11600\n",
      "i= 11700\n",
      "i= 11800\n",
      "i= 11900\n",
      "i= 12000\n",
      "i= 12100\n",
      "i= 12200\n",
      "i= 12300\n",
      "i= 12400\n",
      "i= 12500\n",
      "i= 12600\n",
      "i= 12700\n",
      "i= 12800\n",
      "i= 12900\n",
      "i= 13000\n",
      "i= 13100\n",
      "i= 13200\n",
      "i= 13300\n",
      "i= 13400\n",
      "i= 13500\n",
      "i= 13600\n",
      "i= 13700\n",
      "i= 13800\n",
      "i= 13900\n",
      "i= 14000\n",
      "i= 14100\n",
      "i= 14200\n",
      "i= 14300\n",
      "i= 14400\n",
      "i= 14500\n",
      "i= 14600\n",
      "i= 14700\n",
      "i= 14800\n",
      "i= 14900\n",
      "i= 15000\n",
      "i= 15100\n",
      "i= 15200\n",
      "i= 15300\n",
      "i= 15400\n",
      "i= 15500\n",
      "i= 15600\n",
      "i= 15700\n",
      "i= 15800\n",
      "i= 15900\n",
      "i= 16000\n",
      "i= 16100\n",
      "i= 16200\n",
      "i= 16300\n",
      "i= 16400\n",
      "i= 16500\n",
      "i= 16600\n",
      "i= 16700\n",
      "i= 16800\n",
      "i= 16900\n",
      "i= 17000\n",
      "i= 17100\n",
      "i= 17200\n",
      "i= 17300\n",
      "i= 17400\n",
      "i= 17500\n",
      "i= 17600\n",
      "i= 17700\n",
      "i= 17800\n",
      "i= 17900\n",
      "i= 18000\n",
      "i= 18100\n",
      "i= 18200\n",
      "i= 18300\n",
      "i= 18400\n",
      "i= 18500\n",
      "i= 18600\n",
      "i= 18700\n",
      "i= 18800\n",
      "i= 18900\n",
      "i= 19000\n",
      "i= 19100\n",
      "i= 19200\n",
      "i= 19300\n",
      "i= 19400\n",
      "i= 19500\n",
      "i= 19600\n",
      "i= 19700\n",
      "i= 19800\n",
      "i= 19900\n",
      "i= 20000\n",
      "i= 20100\n",
      "i= 20200\n",
      "i= 20300\n",
      "i= 20400\n",
      "i= 20500\n",
      "i= 20600\n",
      "i= 20700\n",
      "i= 20800\n",
      "i= 20900\n",
      "i= 21000\n",
      "i= 21100\n",
      "i= 21200\n",
      "i= 21300\n",
      "i= 21400\n",
      "i= 21500\n",
      "i= 21600\n",
      "i= 21700\n",
      "i= 21800\n",
      "i= 21900\n",
      "i= 22000\n",
      "i= 22100\n",
      "i= 22200\n",
      "i= 22300\n",
      "i= 22400\n",
      "i= 22500\n",
      "i= 22600\n",
      "i= 22700\n",
      "i= 22800\n",
      "i= 22900\n",
      "i= 23000\n",
      "i= 23100\n",
      "i= 23200\n",
      "i= 23300\n",
      "i= 23400\n",
      "i= 23500\n",
      "i= 23600\n",
      "i= 23700\n",
      "i= 23800\n",
      "i= 23900\n",
      "i= 24000\n",
      "i= 24100\n",
      "i= 24200\n",
      "i= 24300\n",
      "i= 24400\n",
      "i= 24500\n",
      "i= 24600\n",
      "i= 24700\n",
      "i= 24800\n",
      "i= 24900\n",
      "i= 25000\n",
      "i= 25100\n",
      "i= 25200\n",
      "(25293,)\n",
      "[[-0.05102539  0.12060547 -0.01257324 ... -0.26367188 -0.10742188\n",
      "   0.0222168 ]\n",
      " [ 0.15136719  0.25390625  0.22851562 ... -0.05908203 -0.10986328\n",
      "   0.06689453]\n",
      " [ 0.12304688  0.01281738  0.01940918 ... -0.06347656  0.02111816\n",
      "  -0.08251953]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "(418, 300)\n",
      "(25293,)\n",
      "(25293,)\n"
     ]
    }
   ],
   "source": [
    "list_files = np.array(glob.glob(\"./\" + directory + \"/train/*.npz\"))\n",
    "X_train = load(list_files)\n",
    "print(X_train.shape)\n",
    "\n",
    "test_dense_load = sparse.csr_matrix.todense(X_train[0])\n",
    "print(test_dense_load)\n",
    "print(test_dense_load.shape)\n",
    "\n",
    "filename = \"./\" + directory2 +\"/train.npy\"\n",
    "size_texts_train = np.load(filename)\n",
    "print(size_texts_train.shape)\n",
    "\n",
    "filename = \"./\" + directory3 +\"/train.npy\"\n",
    "y_train = np.load(filename)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n",
      "(6555,)\n",
      "(6555,)\n",
      "(6555,)\n"
     ]
    }
   ],
   "source": [
    "list_files = np.array(glob.glob(\"./\" + directory + \"/val/*.npz\"))\n",
    "X_val = load(list_files)\n",
    "print(X_val.shape)\n",
    "\n",
    "filename = \"./\" + directory2 +\"/val.npy\"\n",
    "size_texts_val = np.load(filename)\n",
    "print(size_texts_val.shape)\n",
    "\n",
    "filename = \"./\" + directory3 +\"/val.npy\"\n",
    "y_val = np.load(filename)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répartition des niveaux dans l'ensemble d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  6379\n",
      "1  :  4332\n",
      "2  :  2968\n",
      "3  :  1319\n",
      "4  :  269\n",
      "5  :  10026\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(y_train):\n",
    "    print(i, ' : ', (y_train == i).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répartition des niveaux dans l'ensemble d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  2710\n",
      "1  :  1818\n",
      "2  :  1338\n",
      "3  :  551\n",
      "4  :  124\n",
      "5  :  14\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(y_val):\n",
    "    print(i, ' : ', (y_val == i).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch_X(X, X_lengths, iteration, batch_size):\n",
    "    X_batch = X[iteration*batch_size:(iteration+1)*batch_size]\n",
    "    X_batch_lengths = X_lengths[iteration*batch_size:(iteration+1)*batch_size]\n",
    "    res = np.zeros((batch_size, X_batch[0].shape[0], X_batch[0].shape[1]))\n",
    "    for i in range(len(X_batch)):\n",
    "        #print(X_batch[i])\n",
    "        #print(type(X_batch[i]))\n",
    "        res[i,:,:] = sparse.csr_matrix.todense(X_batch[i])\n",
    "    #X_batch = np.reshape(X_batch, (batch_size, X_batch[0].shape[0], X_batch[0].shape[1]))\n",
    "    return res, X_batch_lengths\n",
    "\n",
    "def get_next_batch_y(y, iteration, batch_size):\n",
    "    y_batch = y[iteration*batch_size:(iteration+1)*batch_size]\n",
    "    return y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_RNN_and_train(X_train, y_train, X_train_lengths, X_val, y_val, X_val_lengths, n_steps, n_inputs, n_neurons=500, activation=tf.nn.relu, \n",
    "                               dropout_in=0, dropout_out=0, class_weights=[1, 1, 1, 1, 1, 1], learning_rate=0.001, \n",
    "                               n_epochs=100, batch_size=200, max_checks_without_progress=3):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_steps, n_inputs], name=\"X\")\n",
    "    seq_lengths = tf.placeholder(tf.int32, [None]) #vecteur avec les nombres de mots dans les textes\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y\")\n",
    "    \n",
    "    dropout_in_placeholder = tf.placeholder_with_default(tf.constant(0.0, dtype=tf.float32), ())\n",
    "    dropout_out_placeholder = tf.placeholder_with_default(tf.constant(0.0, dtype=tf.float32), ())\n",
    "    \n",
    "    basic_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=activation)\n",
    "    basic_cell = tf.contrib.rnn.DropoutWrapper(basic_cell, input_keep_prob=1-dropout_in_placeholder, output_keep_prob=1-dropout_out_placeholder, dtype=tf.float32)\n",
    "    outputs, states = tf.nn.dynamic_rnn(basic_cell, X, sequence_length=seq_lengths, dtype=tf.float32)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=states, units=n_outputs, name=\"logits\")\n",
    "    inference = tf.nn.softmax(logits, name=\"inference\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        #loss = cost(inference, y)\n",
    "\n",
    "        class_weights_tf = tf.constant(class_weights)\n",
    "        weights = tf.gather(class_weights_tf, y)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits, weights=weights)\n",
    "        #xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y) #ancienne version (sans poids)\n",
    "        #loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(tf.cast(logits, tf.float32), y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(\"./summary\", tf.get_default_graph())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    n_batches_per_epoch = X_train.shape[0] // batch_size\n",
    "    print(\"Nombre de batchs par epoch =\", n_batches_per_epoch)\n",
    "    \n",
    "    best_loss = np.infty\n",
    "    checks_without_progress = 0\n",
    "    early_stopping = False\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            for iteration in range(n_batches_per_epoch):\n",
    "                X_batch, seq_len = get_next_batch_X(X_train, X_train_lengths, iteration, batch_size)\n",
    "                y_batch = y_train[iteration*batch_size:(iteration+1)*batch_size]\n",
    "                #print(seq_len)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch, seq_lengths: seq_len, dropout_in_placeholder: dropout_in, dropout_out_placeholder: dropout_out})\n",
    "                #print(sess.run(X_elmo, feed_dict={X: X_batch, y: y_batch, dropout_in_placeholder: dropout_in, dropout_out_placeholder: dropout_out}))\n",
    "                if (iteration+1)%10==0:\n",
    "                    print(\"Batch n°\", iteration+1)\n",
    "                if (iteration+1)%100==0:\n",
    "                    # attention l'évaluation du coût est faite en faisant une moyenne de moyennes,\n",
    "                    # il faut donc que nb_examples_to_evaluate soit un multiple de batch_size_loss_eval\n",
    "                    nb_examples_to_evaluate = np.amin([5000, X_train.shape[0], X_val.shape[0]])\n",
    "                    batch_size_loss_eval = batch_size\n",
    "                    if(nb_examples_to_evaluate % batch_size_loss_eval != 0):\n",
    "                        print(\"WARNING: le nombre d'exemples de l'évaluation n'est pas un multiple de batch_size.\")\n",
    "\n",
    "                    i=0\n",
    "                    k=0\n",
    "                    loss_train=0\n",
    "                    while i < nb_examples_to_evaluate:\n",
    "                        X_batch, seq_len = get_next_batch_X(X_train, X_train_lengths, k, batch_size_loss_eval)\n",
    "                        y_batch = get_next_batch_y(y_train, k, batch_size_loss_eval)\n",
    "                        temp = loss.eval(feed_dict={X: X_batch, y: y_batch, seq_lengths: seq_len})\n",
    "                        #print(temp)\n",
    "                        loss_train = loss_train + temp\n",
    "                        i = i + batch_size_loss_eval\n",
    "                        k = k + 1\n",
    "                    #print(loss_train)\n",
    "                    #print(k)\n",
    "                    loss_train = loss_train / k\n",
    "                    print(epoch, \"Loss training on\", nb_examples_to_evaluate, \"examples:\", loss_train)\n",
    "\n",
    "                    i=0\n",
    "                    k=0\n",
    "                    loss_val=0\n",
    "                    while i < nb_examples_to_evaluate:\n",
    "                        X_batch, seq_len = get_next_batch_X(X_val, X_val_lengths, k, batch_size_loss_eval)\n",
    "                        y_batch = get_next_batch_y(y_val, k, batch_size_loss_eval)\n",
    "                        temp = loss.eval(feed_dict={X: X_batch, y: y_batch, seq_lengths: seq_len})\n",
    "                        loss_val = loss_val + temp\n",
    "                        i = i + batch_size_loss_eval\n",
    "                        k = k + 1\n",
    "                    loss_val = loss_val / k\n",
    "                    print(epoch, \"Loss validation on\", nb_examples_to_evaluate, \"examples:\", loss_val)\n",
    "\n",
    "                    if loss_val < best_loss:\n",
    "                        save_path = saver.save(sess, \"./natural_language_classifier.ckpt\")\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                        if checks_without_progress >= MAX_CHECKS_WITHOUT_PROGRESS:\n",
    "                            print(\"Early stopping!\")\n",
    "                            early_stopping = True\n",
    "                            break\n",
    "                if early_stopping:\n",
    "                    break\n",
    "\n",
    "    return inference, X, seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille vecteur d'un mot = 300\n",
      "Nombre maximal de mots par texte (fixe) = 418\n",
      "(418, 300)\n"
     ]
    }
   ],
   "source": [
    "n_steps = X_train[0].shape[0] #taille des textes (rendue fixe)\n",
    "n_inputs = X_train[0].shape[1] #taille des vecteurs représentant chaque mot\n",
    "print(\"Taille vecteur d'un mot =\", n_inputs)\n",
    "print(\"Nombre maximal de mots par texte (fixe) =\", n_steps)\n",
    "n_neurons = 5000\n",
    "activation = tf.nn.relu\n",
    "n_outputs = 6\n",
    "class_weights = [1, 1, 1, 1, 1, 1] #poids de la fonction de coût\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "MAX_CHECKS_WITHOUT_PROGRESS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de batchs par epoch = 505\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "Batch n° 80\n",
      "Batch n° 90\n",
      "Batch n° 100\n",
      "0 Loss training on 5000 examples: 0.729468397796154\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (50, 351, 300) for Tensor 'X:0', which has shape '(?, 418, 300)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-db983e33b2e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                         \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                                         batch_size=batch_size, max_checks_without_progress=MAX_CHECKS_WITHOUT_PROGRESS)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#0.6 sur les ensembles d'entrainement et d'évaluation avec 500 neurones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-5e8063162458>\u001b[0m in \u001b[0;36mcreate_graph_RNN_and_train\u001b[0;34m(X_train, y_train, X_train_lengths, X_val, y_val, X_val_lengths, n_steps, n_inputs, n_neurons, activation, dropout_in, dropout_out, class_weights, learning_rate, n_epochs, batch_size, max_checks_without_progress)\u001b[0m\n\u001b[1;32m     88\u001b[0m                         \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_batch_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_loss_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_batch_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_loss_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size_loss_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \"\"\"\n\u001b[0;32m--> 656\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5014\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5015\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5016\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1116\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1117\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (50, 351, 300) for Tensor 'X:0', which has shape '(?, 418, 300)'"
     ]
    }
   ],
   "source": [
    "inference, X, seq_lengths = create_graph_RNN_and_train(X_train, y_train, size_texts_train, X_val, y_val, size_texts_val,\n",
    "                                                        n_steps, n_inputs, n_neurons=n_neurons, \n",
    "                                                        activation=activation, class_weights=class_weights,\n",
    "                                                        learning_rate=learning_rate, n_epochs=n_epochs, \n",
    "                                                        batch_size=batch_size, max_checks_without_progress=MAX_CHECKS_WITHOUT_PROGRESS)\n",
    "\n",
    "#0.6 sur les ensembles d'entrainement et d'évaluation avec 500 neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
