{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPw_A2ta3vim"
   },
   "source": [
    "# Chargement des données déjà préparées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les news sont les 10000 derniers fichiers de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vZTDQYA73vim"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s_g3WVMx3viq"
   },
   "outputs": [],
   "source": [
    "def load(list_files):\n",
    "    list_files = np.sort(list_files)\n",
    "    res = []\n",
    "    for i in range(list_files.shape[0]):\n",
    "        if i%100==0 and i > 0:\n",
    "            print(\"i=\", i)\n",
    "        res.append(sparse.load_npz(file=list_files[i]))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "directory = \"texts_matrices_with_news\"\n",
    "directory2 = \"size_texts_with_news\"\n",
    "directory3 = \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_NEWS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n",
      "i= 6600\n",
      "i= 6700\n",
      "i= 6800\n",
      "i= 6900\n",
      "i= 7000\n",
      "i= 7100\n",
      "i= 7200\n",
      "i= 7300\n",
      "i= 7400\n",
      "i= 7500\n",
      "i= 7600\n",
      "i= 7700\n",
      "i= 7800\n",
      "i= 7900\n",
      "i= 8000\n",
      "i= 8100\n",
      "i= 8200\n",
      "i= 8300\n",
      "i= 8400\n",
      "i= 8500\n",
      "i= 8600\n",
      "i= 8700\n",
      "i= 8800\n",
      "i= 8900\n",
      "i= 9000\n",
      "i= 9100\n",
      "i= 9200\n",
      "i= 9300\n",
      "i= 9400\n",
      "i= 9500\n",
      "i= 9600\n",
      "i= 9700\n",
      "i= 9800\n",
      "i= 9900\n",
      "i= 10000\n",
      "i= 10100\n",
      "i= 10200\n",
      "i= 10300\n",
      "i= 10400\n",
      "i= 10500\n",
      "i= 10600\n",
      "i= 10700\n",
      "i= 10800\n",
      "i= 10900\n",
      "i= 11000\n",
      "i= 11100\n",
      "i= 11200\n",
      "i= 11300\n",
      "i= 11400\n",
      "i= 11500\n",
      "i= 11600\n",
      "i= 11700\n",
      "i= 11800\n",
      "i= 11900\n",
      "i= 12000\n",
      "i= 12100\n",
      "i= 12200\n",
      "i= 12300\n",
      "i= 12400\n",
      "i= 12500\n",
      "i= 12600\n",
      "i= 12700\n",
      "i= 12800\n",
      "i= 12900\n",
      "i= 13000\n",
      "i= 13100\n",
      "i= 13200\n",
      "i= 13300\n",
      "i= 13400\n",
      "i= 13500\n",
      "i= 13600\n",
      "i= 13700\n",
      "i= 13800\n",
      "i= 13900\n",
      "i= 14000\n",
      "i= 14100\n",
      "i= 14200\n",
      "i= 14300\n",
      "i= 14400\n",
      "i= 14500\n",
      "i= 14600\n",
      "i= 14700\n",
      "i= 14800\n",
      "i= 14900\n",
      "i= 15000\n",
      "i= 15100\n",
      "i= 15200\n",
      "i= 15300\n",
      "i= 15400\n",
      "i= 15500\n",
      "i= 15600\n",
      "i= 15700\n",
      "i= 15800\n",
      "i= 15900\n",
      "i= 16000\n",
      "i= 16100\n",
      "i= 16200\n",
      "i= 16300\n",
      "i= 16400\n",
      "i= 16500\n",
      "i= 16600\n",
      "i= 16700\n",
      "i= 16800\n",
      "i= 16900\n",
      "i= 17000\n",
      "i= 17100\n",
      "i= 17200\n",
      "i= 17300\n",
      "i= 17400\n",
      "i= 17500\n",
      "i= 17600\n",
      "i= 17700\n",
      "i= 17800\n",
      "i= 17900\n",
      "i= 18000\n",
      "i= 18100\n",
      "i= 18200\n",
      "i= 18300\n",
      "i= 18400\n",
      "i= 18500\n",
      "i= 18600\n",
      "i= 18700\n",
      "i= 18800\n",
      "i= 18900\n",
      "i= 19000\n",
      "i= 19100\n",
      "i= 19200\n",
      "i= 19300\n",
      "i= 19400\n",
      "i= 19500\n",
      "i= 19600\n",
      "i= 19700\n",
      "i= 19800\n",
      "i= 19900\n",
      "i= 20000\n",
      "i= 20100\n",
      "i= 20200\n",
      "i= 20300\n",
      "i= 20400\n",
      "i= 20500\n",
      "i= 20600\n",
      "i= 20700\n",
      "i= 20800\n",
      "i= 20900\n",
      "i= 21000\n",
      "i= 21100\n",
      "i= 21200\n",
      "i= 21300\n",
      "i= 21400\n",
      "i= 21500\n",
      "i= 21600\n",
      "i= 21700\n",
      "i= 21800\n",
      "i= 21900\n",
      "i= 22000\n",
      "i= 22100\n",
      "i= 22200\n",
      "i= 22300\n",
      "i= 22400\n",
      "i= 22500\n",
      "i= 22600\n",
      "i= 22700\n",
      "i= 22800\n",
      "i= 22900\n",
      "i= 23000\n",
      "i= 23100\n",
      "i= 23200\n",
      "i= 23300\n",
      "i= 23400\n",
      "i= 23500\n",
      "i= 23600\n",
      "i= 23700\n",
      "i= 23800\n",
      "i= 23900\n",
      "i= 24000\n",
      "i= 24100\n",
      "i= 24200\n",
      "i= 24300\n",
      "i= 24400\n",
      "i= 24500\n",
      "i= 24600\n",
      "i= 24700\n",
      "i= 24800\n",
      "i= 24900\n",
      "i= 25000\n",
      "i= 25100\n",
      "i= 25200\n",
      "(15293,)\n",
      "[[-0.05102539  0.12060547 -0.01257324 ... -0.26367188 -0.10742188\n",
      "   0.0222168 ]\n",
      " [ 0.15136719  0.25390625  0.22851562 ... -0.05908203 -0.10986328\n",
      "   0.06689453]\n",
      " [ 0.12304688  0.01281738  0.01940918 ... -0.06347656  0.02111816\n",
      "  -0.08251953]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "(418, 300)\n",
      "(25293,)\n",
      "(15293,)\n"
     ]
    }
   ],
   "source": [
    "list_files = np.array(glob.glob(\"./\" + directory + \"/train/*.npz\"))\n",
    "X_train = load(list_files)\n",
    "X_train = X_train[:-(10000-NB_NEWS)]\n",
    "print(X_train.shape)\n",
    "\n",
    "test_dense_load = sparse.csr_matrix.todense(X_train[0])\n",
    "print(test_dense_load)\n",
    "print(test_dense_load.shape)\n",
    "\n",
    "filename = \"./\" + directory2 +\"/train.npy\"\n",
    "size_texts_train = np.load(filename)\n",
    "print(size_texts_train.shape)\n",
    "\n",
    "filename = \"./\" + directory3 +\"/train.npy\"\n",
    "y_train = np.load(filename)\n",
    "y_train = y_train[:-(10000-NB_NEWS)]\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n",
      "(6555,)\n",
      "(6555,)\n",
      "(6555,)\n"
     ]
    }
   ],
   "source": [
    "list_files = np.array(glob.glob(\"./\" + directory + \"/val/*.npz\"))\n",
    "X_val = load(list_files)\n",
    "print(X_val.shape)\n",
    "\n",
    "filename = \"./\" + directory2 +\"/val.npy\"\n",
    "size_texts_val = np.load(filename)\n",
    "print(size_texts_val.shape)\n",
    "\n",
    "filename = \"./\" + directory3 +\"/val.npy\"\n",
    "y_val = np.load(filename)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répartition des niveaux dans l'ensemble d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  6379\n",
      "1  :  4332\n",
      "2  :  2968\n",
      "3  :  1319\n",
      "4  :  269\n",
      "5  :  26\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(y_train):\n",
    "    print(i, ' : ', (y_train == i).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répartition des niveaux dans l'ensemble d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  2710\n",
      "1  :  1818\n",
      "2  :  1338\n",
      "3  :  551\n",
      "4  :  124\n",
      "5  :  14\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(y_val):\n",
    "    print(i, ' : ', (y_val == i).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 10000 derniers textes de X_train sont les news. On mélange pour avoir une meilleur répartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15293,)\n",
      "[    0     1     2 ... 15290 15291 15292]\n",
      "[11745  8753  5813 ... 10910   979  1378]\n",
      "(15293,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "s = np.arange(X_train.shape[0])\n",
    "print(s)\n",
    "\n",
    "np.random.shuffle(s)\n",
    "print(s)\n",
    "X_train = X_train[s]\n",
    "y_train = y_train[s]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch_X(X, X_lengths, iteration, batch_size):\n",
    "    X_batch = X[iteration*batch_size:(iteration+1)*batch_size]\n",
    "    X_batch_lengths = X_lengths[iteration*batch_size:(iteration+1)*batch_size]\n",
    "    res = np.zeros((X_batch.shape[0], X_batch[0].shape[0], X_batch[0].shape[1]))\n",
    "    for i in range(len(X_batch)):\n",
    "        #print(X_batch[i])\n",
    "        #print(type(X_batch[i]))\n",
    "        res[i,:,:] = sparse.csr_matrix.todense(X_batch[i])\n",
    "    #X_batch = np.reshape(X_batch, (batch_size, X_batch[0].shape[0], X_batch[0].shape[1]))\n",
    "    return res, X_batch_lengths\n",
    "\n",
    "def get_next_batch_y(y, iteration, batch_size):\n",
    "    y_batch = y[iteration*batch_size:(iteration+1)*batch_size]\n",
    "    return y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_RNN_and_train(X_train, y_train, X_train_lengths, X_val, y_val, X_val_lengths, n_steps, n_inputs, n_neurons=500, activation=tf.nn.relu, \n",
    "                               dropout_in=0, dropout_out=0, class_weights=[1, 1, 1, 1, 1, 1], learning_rate=0.001, \n",
    "                               n_epochs=100, batch_size=200, max_checks_without_progress=3):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_steps, n_inputs], name=\"X\")\n",
    "    seq_lengths = tf.placeholder(tf.int32, [None]) #vecteur avec les nombres de mots dans les textes\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y\")\n",
    "    \n",
    "    dropout_in_placeholder = tf.placeholder_with_default(tf.constant(0.0, dtype=tf.float32), ())\n",
    "    dropout_out_placeholder = tf.placeholder_with_default(tf.constant(0.0, dtype=tf.float32), ())\n",
    "    \n",
    "    basic_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=activation)\n",
    "    basic_cell = tf.contrib.rnn.DropoutWrapper(basic_cell, input_keep_prob=1-dropout_in_placeholder, output_keep_prob=1-dropout_out_placeholder, dtype=tf.float32)\n",
    "    outputs, states = tf.nn.dynamic_rnn(basic_cell, X, sequence_length=seq_lengths, dtype=tf.float32)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=states, units=n_outputs, name=\"logits\")\n",
    "    inference = tf.nn.softmax(logits, name=\"inference\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        #loss = cost(inference, y)\n",
    "\n",
    "        class_weights_tf = tf.constant(class_weights)\n",
    "        weights = tf.gather(class_weights_tf, y)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits, weights=weights)\n",
    "        #xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y) #ancienne version (sans poids)\n",
    "        #loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(tf.cast(logits, tf.float32), y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(\"./summary\", tf.get_default_graph())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    n_batches_per_epoch = X_train.shape[0] // batch_size\n",
    "    print(\"Nombre de batchs par epoch =\", n_batches_per_epoch)\n",
    "    \n",
    "    best_loss = np.infty\n",
    "    checks_without_progress = 0\n",
    "    early_stopping = False\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            for iteration in range(n_batches_per_epoch):\n",
    "                X_batch, seq_len = get_next_batch_X(X_train, X_train_lengths, iteration, batch_size)\n",
    "                y_batch = y_train[iteration*batch_size:(iteration+1)*batch_size]\n",
    "                #print(seq_len)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch, seq_lengths: seq_len, dropout_in_placeholder: dropout_in, dropout_out_placeholder: dropout_out})\n",
    "                #print(sess.run(X_elmo, feed_dict={X: X_batch, y: y_batch, dropout_in_placeholder: dropout_in, dropout_out_placeholder: dropout_out}))\n",
    "                if (iteration+1)%10==0:\n",
    "                    print(\"Batch n°\", iteration+1)\n",
    "            #if (iteration+1)%100==0:\n",
    "            # attention l'évaluation du coût est faite en faisant une moyenne de moyennes,\n",
    "            # il faut donc que nb_examples_to_evaluate soit un multiple de batch_size_loss_eval\n",
    "            nb_examples_to_evaluate = np.amin([5000, X_train.shape[0], X_val.shape[0]])\n",
    "            batch_size_loss_eval = batch_size\n",
    "            #if(nb_examples_to_evaluate % batch_size_loss_eval != 0):\n",
    "                #print(\"WARNING: le nombre d'exemples de l'évaluation n'est pas un multiple de batch_size.\")\n",
    "\n",
    "            i=0\n",
    "            k=0\n",
    "            loss_train=0\n",
    "            while i < nb_examples_to_evaluate:\n",
    "                X_batch, seq_len = get_next_batch_X(X_train, X_train_lengths, k, batch_size_loss_eval)\n",
    "                y_batch = get_next_batch_y(y_train, k, batch_size_loss_eval)\n",
    "                temp = loss.eval(feed_dict={X: X_batch, y: y_batch, seq_lengths: seq_len})\n",
    "                #print(temp)\n",
    "                loss_train = loss_train + temp\n",
    "                i = i + batch_size_loss_eval\n",
    "                k = k + 1\n",
    "            #print(loss_train)\n",
    "            #print(k)\n",
    "            loss_train = loss_train / k\n",
    "            print(epoch, \"Loss training on\", nb_examples_to_evaluate, \"examples:\", loss_train)\n",
    "\n",
    "            i=0\n",
    "            k=0\n",
    "            loss_val=0\n",
    "            while i < nb_examples_to_evaluate:\n",
    "                X_batch, seq_len = get_next_batch_X(X_val, X_val_lengths, k, batch_size_loss_eval)\n",
    "                y_batch = get_next_batch_y(y_val, k, batch_size_loss_eval)\n",
    "                temp = loss.eval(feed_dict={X: X_batch, y: y_batch, seq_lengths: seq_len})\n",
    "                loss_val = loss_val + temp\n",
    "                i = i + batch_size_loss_eval\n",
    "                k = k + 1\n",
    "            loss_val = loss_val / k\n",
    "            print(epoch, \"Loss validation on\", nb_examples_to_evaluate, \"examples:\", loss_val)\n",
    "\n",
    "            if loss_val < best_loss:\n",
    "                save_path = saver.save(sess, \"./natural_language_classifier.ckpt\")\n",
    "                best_loss = loss_val\n",
    "                checks_without_progress = 0\n",
    "            else:\n",
    "                checks_without_progress += 1\n",
    "                if checks_without_progress >= MAX_CHECKS_WITHOUT_PROGRESS:\n",
    "                    print(\"Early stopping!\")\n",
    "                    early_stopping = True\n",
    "                    break\n",
    "                #if early_stopping:\n",
    "                    #break\n",
    "\n",
    "    return inference, X, seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15293,)\n",
      "(418, 300)\n",
      "Taille vecteur d'un mot = 300\n",
      "Nombre maximal de mots par texte (fixe) = 418\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train[0].shape)\n",
    "n_steps = X_train[0].shape[0] #taille des textes (rendue fixe)\n",
    "n_inputs = X_train[0].shape[1] #taille des vecteurs représentant chaque mot\n",
    "print(\"Taille vecteur d'un mot =\", n_inputs)\n",
    "print(\"Nombre maximal de mots par texte (fixe) =\", n_steps)\n",
    "n_neurons = 1000\n",
    "activation = tf.nn.relu\n",
    "dropout_in = 0.5\n",
    "dropout_out = 0.5\n",
    "\n",
    "n_outputs = 6\n",
    "class_weights = [1, 1, 1, 1, 1, 1] #poids de la fonction de coût\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "MAX_CHECKS_WITHOUT_PROGRESS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de batchs par epoch = 76\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "0 Loss training on 5000 examples: 0.8463095307350159\n",
      "0 Loss validation on 5000 examples: 0.8980673623085021\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "1 Loss training on 5000 examples: 0.6118905520439148\n",
      "1 Loss validation on 5000 examples: 0.5864042615890503\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "2 Loss training on 5000 examples: 0.4742919993400574\n",
      "2 Loss validation on 5000 examples: 0.5334675860404968\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "3 Loss training on 5000 examples: 0.3595926630496979\n",
      "3 Loss validation on 5000 examples: 0.43179181337356565\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "4 Loss training on 5000 examples: 0.30325991570949556\n",
      "4 Loss validation on 5000 examples: 0.3309844404459\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "5 Loss training on 5000 examples: 0.255349782705307\n",
      "5 Loss validation on 5000 examples: 0.35778380930423737\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "6 Loss training on 5000 examples: 0.21278769850730897\n",
      "6 Loss validation on 5000 examples: 0.26508794486522674\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "7 Loss training on 5000 examples: 0.18304964184761047\n",
      "7 Loss validation on 5000 examples: 0.2751568901538849\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "8 Loss training on 5000 examples: 0.14315841376781463\n",
      "8 Loss validation on 5000 examples: 0.26000227153301236\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "9 Loss training on 5000 examples: 0.12800123393535615\n",
      "9 Loss validation on 5000 examples: 0.22803639590740205\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "10 Loss training on 5000 examples: 0.11034732699394226\n",
      "10 Loss validation on 5000 examples: 0.2314801800251007\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "11 Loss training on 5000 examples: 0.10307310685515404\n",
      "11 Loss validation on 5000 examples: 0.2187988618016243\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "12 Loss training on 5000 examples: 0.08360730215907097\n",
      "12 Loss validation on 5000 examples: 0.22840890884399415\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "13 Loss training on 5000 examples: 0.08240054175257683\n",
      "13 Loss validation on 5000 examples: 0.23175156414508818\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "14 Loss training on 5000 examples: 0.07594387471675873\n",
      "14 Loss validation on 5000 examples: 0.28070623099803926\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "15 Loss training on 5000 examples: 0.05494359046220779\n",
      "15 Loss validation on 5000 examples: 0.2525991028547287\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "16 Loss training on 5000 examples: 0.033296487890183926\n",
      "16 Loss validation on 5000 examples: 0.24909798473119735\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "17 Loss training on 5000 examples: 0.02847322331741452\n",
      "17 Loss validation on 5000 examples: 0.2356175473332405\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "18 Loss training on 5000 examples: 0.020962252262979746\n",
      "18 Loss validation on 5000 examples: 0.24150377333164216\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "19 Loss training on 5000 examples: 0.0222074824757874\n",
      "19 Loss validation on 5000 examples: 0.28246725976467135\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "20 Loss training on 5000 examples: 0.02723334863781929\n",
      "20 Loss validation on 5000 examples: 0.3084212666749954\n",
      "Batch n° 10\n",
      "Batch n° 20\n",
      "Batch n° 30\n",
      "Batch n° 40\n",
      "Batch n° 50\n",
      "Batch n° 60\n",
      "Batch n° 70\n",
      "21 Loss training on 5000 examples: 0.0190996983833611\n",
      "21 Loss validation on 5000 examples: 0.30107907086610797\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "inference, X, seq_lengths = create_graph_RNN_and_train(X_train, y_train, size_texts_train, X_val, y_val, size_texts_val,\n",
    "                                                        n_steps, n_inputs, n_neurons=n_neurons, \n",
    "                                                        activation=activation, dropout_in=dropout_in,\n",
    "                                                        dropout_out=dropout_out, class_weights=class_weights,\n",
    "                                                        learning_rate=learning_rate, n_epochs=n_epochs, \n",
    "                                                        batch_size=batch_size, max_checks_without_progress=MAX_CHECKS_WITHOUT_PROGRESS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.array([[0,1,2,3,4,6],[1,0,1,4,5,8],[3,2,0,3,5,8],[10,7,5,0,2,7],[20,16,12,4,0,8],[44,38,32,19,13,0]])\n",
    "names = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=['A1', 'A2', 'B1', 'B2', 'C1', 'C2'],\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print_confusion = True\n",
    "def cost(y_pred, y_true, normalize=True):\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    res = (1/y_true.shape[0]) * np.sum(np.multiply(costs, confusion))\n",
    "    \n",
    "    if print_confusion:\n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cnf_matrix, normalize=normalize, title='Normalized confusion matrix')\n",
    "\n",
    "        plt.show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./natural_language_classifier.ckpt\n",
      "Normalized confusion matrix\n",
      "[[0.97 0.02 0.01 0.   0.   0.  ]\n",
      " [0.03 0.93 0.02 0.01 0.   0.  ]\n",
      " [0.   0.03 0.9  0.04 0.03 0.  ]\n",
      " [0.   0.02 0.06 0.85 0.07 0.  ]\n",
      " [0.01 0.06 0.08 0.1  0.75 0.  ]\n",
      " [0.07 0.07 0.07 0.21 0.57 0.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26254767353165526\n"
     ]
    }
   ],
   "source": [
    "print_confusion = True\n",
    "batch_size = 50\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./natural_language_classifier.ckpt\")\n",
    "    i=0\n",
    "    iteration=0\n",
    "    y_pred = []\n",
    "    while i < X_val.shape[0]:\n",
    "        X_batch, seq_len = get_next_batch_X(X_val, size_texts_val, iteration, batch_size)\n",
    "        #print(X_batch)\n",
    "        temp = sess.run(inference, feed_dict={X: X_batch, seq_lengths: seq_len})\n",
    "        #print(temp)\n",
    "        y_pred.extend(np.argmax(temp, axis=1))\n",
    "        #print(y_pred)\n",
    "        i = i + batch_size\n",
    "        iteration = iteration + 1\n",
    "print(cost(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
