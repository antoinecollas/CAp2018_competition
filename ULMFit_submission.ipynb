{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ULMFiT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papiers associés:\n",
    "- [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/abs/1708.02182)\n",
    "- [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../fastai/\")\n",
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "PATH=Path('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27310, 60)\n",
      "C2  :  50\n",
      "C1  :  491\n",
      "B2  :  2337\n",
      "B1  :  5383\n",
      "A2  :  7688\n",
      "A1  :  11361\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(PATH/'train_cap2018.csv')\n",
    "real_test_dataset = pd.read_csv(PATH/'test_cap2018.csv')\n",
    "print(dataset.shape)\n",
    "for i in dataset['level1'].unique():\n",
    "    print(i, ' : ', (dataset['level1'] == i).values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27310, 60)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "random_state = 42\n",
    "train = shuffle(dataset, random_state=random_state)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27310,)\n",
      "(27310,)\n",
      "(13656,)\n"
     ]
    }
   ],
   "source": [
    "y = train['level1']\n",
    "X = train['fulltext']\n",
    "real_test_X = real_test_dataset['fulltext']\n",
    "#real_test_y = real_test_dataset['level1']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(real_test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y.replace({\"A1\": 0, \"A2\" : 1, \"B1\" : 2, \"B2\" : 3, \"C1\" : 4, \"C2\" : 5}))\n",
    "CLASSES = [0, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Découpage de l'entrainement en entrainement + validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8447     \\n\\n      Shopping addictionFrom: catherineTo:...\n",
      "5545     \\n\\n      NAME : GavinBestFanEMAIL ADDRESS : x...\n",
      "25908    \\n\\n      Hi, My name is Marina. I'm twenty-fi...\n",
      "13235    \\n\\n      I think that travel around the world...\n",
      "13118    \\n\\n      At 20 september, Madonna will play i...\n",
      "Name: fulltext, dtype: object\n",
      "(21848,)\n",
      "(21848,)\n",
      "(5462,)\n",
      "(5462,)\n"
     ]
    }
   ],
   "source": [
    "training_size = 0.8\n",
    "\n",
    "X_train = X[0:int(X.shape[0]*training_size)]\n",
    "y_train = y[0:int(y.shape[0]*training_size)]\n",
    "\n",
    "X_val = X[int(X.shape[0]*training_size):]\n",
    "y_val = y[int(y.shape[0]*training_size):]\n",
    "\n",
    "print(X_train.head())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      Shopping addictionFrom: catherineTo: xxx@net.comYou have to find other things to do. For  exemple, you can walk in the forest or go to the swimming pool.You should ask you  each time  you want to buy: is it important to have this object?When you want to go shopping, you should have  just a little money. You could't buy when you won't  have money.Good luck.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trn_texts = list(X_train)\n",
    "trn_labels = list(y_train)\n",
    "real_test_texts = list(real_test_X)\n",
    "\n",
    "val_texts = list(X_val)\n",
    "val_labels = list(y_val)\n",
    "\n",
    "print(trn_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ULMFiT/classes/\n",
    "!mkdir -p ULMFiT/lm/\n",
    "\n",
    "CLAS_PATH=Path('ULMFiT/classes/')\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LM_PATH=Path('ULMFiT/lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21848, 5462)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts),len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['labels','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\n      Shopping addictionFrom: catherineTo:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n      NAME : GavinBestFanEMAIL ADDRESS : x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n      Hi, My name is Marina. I'm twenty-fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\n      I think that travel around the world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\n      At 20 september, Madonna will play i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       1  \\n\\n      Shopping addictionFrom: catherineTo:...\n",
       "1       2  \\n\\n      NAME : GavinBestFanEMAIL ADDRESS : x...\n",
       "2       0  \\n\\n      Hi, My name is Marina. I'm twenty-fi...\n",
       "3       1  \\n\\n      I think that travel around the world...\n",
       "4       1  \\n\\n      At 20 september, Madonna will play i..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)\n",
    "df_real_test = pd.DataFrame({'text':real_test_texts, 'labels':[0]*len(real_test_texts)}, columns=col_names)\n",
    "\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH/'val.csv', header=False, index=False)\n",
    "df_real_test.to_csv(CLAS_PATH/'real_test.csv', header=False, index=False)\n",
    "\n",
    "(CLAS_PATH/'classes.txt').open('w').writelines(f'{o}\\n' for o in CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commençons par créer les données pour le modèle de langue (LM). L'objectif du LM est d'apprendre la structure de la langue anglaise. Il apprend le langage en essayant de prédire le mot suivant à partir d'un ensemble de mots précédents (ngrammes). Comme le LM ne classe pas les revues, les étiquettes peuvent être ignorées.\n",
    "\n",
    "Le LM peut bénéficier de toutes les données textuelles. On utilise donc les quatres ensembles: l'entrainement, la validation, le \"faux\" test et le \"vrai\" test (pour lequel nous n'avons pas les niveaux des textes).\n",
    "\n",
    "Nous concaténons d'abord tous les textes (y compris ceux pour lesquels nous devons évaluer le niveau de langue!). Puis nous utilisons sklearn pour diviser les textes en 90% d'entrainement et 10% de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13656"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test = pd.read_csv(PATH/'test_cap2018.csv')\n",
    "real_test = list(real_test['fulltext'])\n",
    "len(real_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21848\n",
      "5462\n",
      "13656\n"
     ]
    }
   ],
   "source": [
    "print(len(trn_texts))\n",
    "print(len(val_texts))\n",
    "print(len(real_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(\n",
    "    np.concatenate([trn_texts,val_texts,real_test]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36869, 4097)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
    "\n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'val.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, nous commençons par nettoyer le texte. Il y a 2 activités principales que nous devons réaliser :\n",
    "\n",
    "- Nettoyer le texte.\n",
    "- Utiliser [spacy](http://spacy.io) pour \"tokeniser\" les données. (Une parallélisation est ajoutée par fastai).\n",
    "\n",
    "Chunksize permet de ne pas charger toutes données en mémoire. Le chargement se fait au fur et à mesure (dataframe itérable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('\\n\\n', \"\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(LM_PATH/'val.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! pip install spacy && python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(LM_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 179532),\n",
       " (',', 120723),\n",
       " ('i', 111946),\n",
       " ('the', 106371),\n",
       " ('and', 76986),\n",
       " ('to', 69786),\n",
       " ('a', 65954),\n",
       " ('in', 53481),\n",
       " ('my', 44018),\n",
       " ('is', 40898),\n",
       " ('you', 40268),\n",
       " ('1', 38852),\n",
       " ('\\n', 36869),\n",
       " ('xbos', 36869),\n",
       " ('xfld', 36869),\n",
       " ('of', 34815),\n",
       " ('it', 28896),\n",
       " ('for', 25738),\n",
       " (\"'s\", 23753),\n",
       " ('are', 23231),\n",
       " ('have', 22093),\n",
       " ('at', 17980),\n",
       " ('with', 17783),\n",
       " (\"'m\", 16177),\n",
       " ('that', 15848)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le vocab est l'ensemble des tokens de notre jeu de données. Le vocabulaire nous fournit un moyen de remplacer simplement chaque mot de nos ensembles de données par un entier unique appelé index.\n",
    "\n",
    "Dans un grand corpus de données, on peut trouver des mots rares qui ne sont utilisés que quelques fois dans l'ensemble des données. Nous rejetons ces mots rares (donc on ne pourra pas apprendre greand chose).\n",
    "\n",
    "Ici, nous avons fixé une fréquence minimale d'apparition à 2 fois. La taille de 60000 est résultat empirique que l'on retrouve régulièrement dans la communauté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16985"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "#print(itos)\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons une map inversée appelée stoi qui est utile pour rechercher l'index d'un token donné. stoi a le même nombre d'éléments qu'itos. Nous utilisons un conteneur appelé [collections.defaultdict](https://docs.python.org/2/library/collections.html#collections.defaultdict) pour stocker nos cartes stoi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16985"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "#print(stoi)\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante permet une liste des textes. Chaque est texte est lui même une liste contenant les index des tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tok_trn)\n",
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "#print(trn_lm)\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16985, 36869)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikitext103 conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant construire un modèle de langue anglaise pour notre corpus. Nous pourrions partir de zéro et essayer d'apprendre la structure de la langue anglaise. Mais nous utilisons une technique appelée \"transfer learning\" pour faciliter ce processus. Dans l'apprentissage par transfert, un LM qui a déjà été entrainé sur un grand corpus générique (comme les articles wikipedia) peut être utilisé pour transférer ses connaissances à un LM cible puis les poids sont affinés sur le corpus cible.\n",
    "\n",
    "Notre LM source est le LM wikitext103 créé par Stephen Merity @ Salesforce research. [Lien vers l'ensemble des données](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n",
    "Le modèle de langue pour wikitext103 (AWD LSTM) a été entrainé et les poids peuvent être téléchargés ici : [Lien](http://files.fast.ai/models/wt103/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! wget -nH -r -np -P {PATH} http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les poids du LM pré-entraîné ont une taille de 400, 1150 unités cachées et 3 couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous calculons la moyenne des poids de l'encodeur \"layer0\". Ceci peut être utilisé pour assigner des poids à des tokens inconnus lorsque nous ferons le transfert sur notre corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous récupérons la table faisant la correspondance entre les index et les mots du wikitext103. (Les équivalences ne sont pas les mêmes que celles que nous avons établies précédemment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'essayer de transférer les connaissances de wikitext à notre corpus, nous faisons correspondre les mots de vocabulaire et leurs index. Nous utilisons à nouveau le conteneur defaultdict, pour attribuer des poids moyens à des token inconnus (qui n'existent pas dans wikitext103)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    #print(w)\n",
    "    r = stoi2[w]\n",
    "    #print(r)\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m\n",
    "#print(new_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous écrasons maintenant les poids dans wgts.\n",
    "Le module de décodeur est également chargé avec les mêmes poids que l'encodeur (weight tying)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La longueur de bptt (backpropagation through time) suit une loi normale d'espérance 70 et de variance 5 (à vérifier). Cela permet d'une epoch à l'autre de ne pas refaire systématiquement les mêmes prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=300\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif du LM est d'apprendre à prédire un token compte tenu d'un ensemble précédent de tokens. Nous prenons toutes les données (y compris l'ensemble de test pour lequel nous n'avons pas les étiquettes), nous les concaténons pour former une longue chaîne de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous configurons les dropouts pour le modèle - ces valeurs ont été choisies après expérimentation. S'il y a besoin d'affiner les réglages, il suffit de modifier le coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous entrainons d'abord la dernière couche d'intégration afin que les tokens manquants, initialisés avec des poids moyens, soient entrainés correctement. On freeze tout sauf la dernière couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.load_state_dict(wgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set learning rates and fit our LM. We first run one epoch to tune the last layer which contains the embedding weights. This should help the missing tokens in the wikitext103 learn better weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-2\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4c969ee9f444b7ac891860cdd7f187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      4.043388   3.634404   0.32804   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.6344]), 0.3280399502830559]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we print out accuracy and keep track of how often we end up predicting the target word correctly. While this is a good metric to check, it is not part of our loss function as it can get quite bumpy. We only minimize cross-entropy loss in the LM.\n",
    "\n",
    "The exponent of the cross-entropy loss is called the perplexity of the LM. (low perplexity is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante permet de trouver un bon taux d'apprentissage (voir [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/pdf/1506.01186.pdf))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d32fa692bd4d2d9f85087fb469545d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 75/145 [00:27<00:25,  2.74it/s, loss=24.5]"
     ]
    }
   ],
   "source": [
    "learner.lr_find(start_lr=lrs/100, end_lr=lrs*100, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd85bbb65e204b20ad266130819e8e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      3.281816   3.030241   0.404347  \n",
      "    1      3.024904   2.904267   0.419938                   \n",
      "    2      2.856119   2.864845   0.427644                   \n",
      "    3      2.737507   2.821044   0.432446                   \n",
      "    4      2.63331    2.820358   0.434684                   \n",
      "    5      2.536621   2.820038   0.435314                   \n",
      "    6      2.454776   2.814853   0.438141                   \n",
      "    7      2.375022   2.800956   0.440251                   \n",
      "    8      2.316772   2.803033   0.441673                   \n",
      "    9      2.260695   2.809033   0.44305                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.80903]), 0.4430504651630626]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lr, 1, wds=wd, use_clr=(20,10), cycle_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the trained model weights and separately save the encoder part of the LM model as well. This will serve as our backbone in the classification task model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier model is basically a linear layer custom head on top of the LM backbone. Setting up the classifier data is similar to the LM data setup except that we cannot use the unsup movie reviews this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(CLAS_PATH/'val.csv', header=None, chunksize=chunksize)\n",
    "df_real_test = pd.read_csv(CLAS_PATH/'real_test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)\n",
    "tok_real_test, real_test_labels = get_all(df_real_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_real_test.npy', tok_real_test)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'real_test_labels.npy', real_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13656\n"
     ]
    }
   ],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')\n",
    "tok_real_test = np.load(CLAS_PATH/'tmp'/'tok_real_test.npy')\n",
    "print(len(tok_real_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16985"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])\n",
    "real_test_clas = np.array([[stoi[o] for o in p] for p in tok_real_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'val_ids.npy', val_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'real_test_ids.npy', real_test_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our final model, a classifier which is really a custom linear head over our trained backbone. The steps to create the classifier model are similar to the ones for the LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')\n",
    "real_test_clas = np.load(CLAS_PATH/'tmp'/'real_test_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))\n",
    "real_test_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'real_test_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 ... 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classifier, unlike LM, we need to read a movie review at a time and learn to predict the it's sentiment as pos/neg. We do not deal with equal bptt size batches, so we have to pad the sequences to the same length in each batch. To create batches of similar sized movie reviews, we use a sortish sampler method invented by [@Smerity](https://twitter.com/Smerity) and [@jekbradbury](https://twitter.com/jekbradbury)\n",
    "\n",
    "The sortishSampler cuts down the overall number of padding tokens the classifier ends up seeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "real_test_ds = TextDataset(real_test_clas, real_test_labels)\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "real_test_dl = DataLoader(real_test_ds, bs, transpose=True, num_workers=1, pad_idx=1)\n",
    "md = ModelData(PATH, trn_dl, val_dl, real_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13656\n",
      "13656\n",
      "13656\n"
     ]
    }
   ],
   "source": [
    "print(len(real_test_clas))\n",
    "print(len(real_test_ds.x))\n",
    "print(len(real_test_ds.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1\n",
    "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 150, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3], \n",
    "          #bidir=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "#wd = 0\n",
    "learn.load_encoder('lm1_enc')\n",
    "#wgts['0.rnns.0.module.weight_ih_l0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=8, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.array([[0,1,2,3,4,6],[1,0,1,4,5,8],[3,2,0,3,5,8],[10,7,5,0,2,7],[20,16,12,4,0,8],[44,38,32,19,13,0]])\n",
    "names = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=['A1', 'A2', 'B1', 'B2', 'C1', 'C2'],\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print_confusion = True\n",
    "def cost(y_pred, y_true):\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    res = (1/y_true.shape[0]) * np.sum(np.multiply(costs, confusion))\n",
    "    res_by_level = np.sum(np.multiply(costs, confusion), axis=1)\n",
    "    \n",
    "    if print_confusion:\n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cnf_matrix, normalize=False, title='Confusion matrix')\n",
    "        plt.show()\n",
    "        plot_confusion_matrix(cnf_matrix, normalize=True, title='Normalized confusion matrix')\n",
    "        plt.show()\n",
    "    return res, res_by_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_val2 = learn.predict_with_targs()\n",
    "#print(y_pred)\n",
    "y_pred = np.argmax(learn.predict_dl(val_dl), axis=1)\n",
    "print(val_labels)\n",
    "print(len(y_pred))\n",
    "print(y_pred)\n",
    "print(y_val)\n",
    "print(y_val2)\n",
    "print(cost(y_pred, y_val2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(learn.predict_dl(real_test_dl), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)\n",
    "print(len(y_pred))\n",
    "#y = np.array(real_test_y.replace({\"A1\": 0, \"A2\" : 1, \"B1\" : 2, \"B2\" : 3, \"C1\" : 4, \"C2\" : 5}))\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(y_pred))\n",
    "#print(real_test_y.shape)\n",
    "#print(cost(y_pred, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_level(int_level):\n",
    "    str_level = \"\"\n",
    "    if int_level==0:\n",
    "        str_level = \"A1\"\n",
    "    elif int_level==1:\n",
    "        str_level = \"A2\"\n",
    "    elif int_level==2:\n",
    "        str_level = \"B1\"\n",
    "    elif int_level==3:\n",
    "        str_level = \"B2\"\n",
    "    elif int_level==4:\n",
    "        str_level = \"C1\"\n",
    "    elif int_level==5:\n",
    "        str_level = \"C2\"\n",
    "    return str_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir submissions\n",
    "import csv\n",
    "i = 0\n",
    "with open('submissions/submission.csv', 'w') as csvfile:\n",
    "    fieldnames = ['text', 'level']\n",
    "    writer = csv.DictWriter(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(y_pred)):\n",
    "        writer.writerow({fieldnames[0]: str(i), fieldnames[1]: replace_level(y_pred[i])})\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat submissions/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": "0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
