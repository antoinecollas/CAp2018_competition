{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzxJNqHi3vdY"
   },
   "source": [
    "# Lecture des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3w4l-a5M3vdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53191,
     "status": "ok",
     "timestamp": 1526220903624,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "urpwuZz33vdm",
    "outputId": "74eb6038-8f3a-448c-a431-2b01fadc5f7d"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/train_cap2018.csv')\n",
    "dataset1 = pd.concat([pd.read_csv('data/articles1.csv'), pd.read_csv('data/articles2.csv'), pd.read_csv('data/articles3.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1526220904153,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "GWkU0ZCM3vdu",
    "outputId": "1601f797-8599-4569-f9c2-cf6db9a90ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27310, 60)\n",
      "(142570, 10)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1526158471398,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "1KDetbuH3vey",
    "outputId": "4fbcf80b-8c4b-4967-e77a-c70e18af62c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2  :  50\n",
      "C1  :  491\n",
      "B2  :  2337\n",
      "B1  :  5383\n",
      "A2  :  7688\n",
      "A1  :  11361\n"
     ]
    }
   ],
   "source": [
    "for i in dataset['level1'].unique():\n",
    "    print(i, ' : ', (dataset['level1'] == i).values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1526221374891,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "SsgrrYt-3vd6",
    "outputId": "9f056c04-db18-4e8d-a89b-47cc149a1988"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulltext</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>letters.all</th>\n",
       "      <th>syllables</th>\n",
       "      <th>punct</th>\n",
       "      <th>avg.sentc.length</th>\n",
       "      <th>avg.word.length</th>\n",
       "      <th>avg.syll.word</th>\n",
       "      <th>sntc.per.word</th>\n",
       "      <th>...</th>\n",
       "      <th>Maas lgV0</th>\n",
       "      <th>MATTR</th>\n",
       "      <th>MSTTR</th>\n",
       "      <th>MTLD</th>\n",
       "      <th>Root TTR</th>\n",
       "      <th>Summer</th>\n",
       "      <th>TTR.1</th>\n",
       "      <th>Uber index</th>\n",
       "      <th>Yule's K</th>\n",
       "      <th>level1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n      The Eiffel Tower The Eiffel Tower is...</td>\n",
       "      <td>16</td>\n",
       "      <td>233</td>\n",
       "      <td>1116</td>\n",
       "      <td>363</td>\n",
       "      <td>32</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>4.789700</td>\n",
       "      <td>1.557940</td>\n",
       "      <td>0.068670</td>\n",
       "      <td>...</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>70.74</td>\n",
       "      <td>8.98</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.59</td>\n",
       "      <td>24.30</td>\n",
       "      <td>146.62</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n      The Court Green burglar arrested A 2...</td>\n",
       "      <td>7</td>\n",
       "      <td>180</td>\n",
       "      <td>866</td>\n",
       "      <td>268</td>\n",
       "      <td>18</td>\n",
       "      <td>25.714286</td>\n",
       "      <td>4.811111</td>\n",
       "      <td>1.488889</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>...</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>107.12</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>26.14</td>\n",
       "      <td>141.98</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n      Thank you for giving us the opportun...</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>861</td>\n",
       "      <td>269</td>\n",
       "      <td>20</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.783333</td>\n",
       "      <td>1.494444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>161.93</td>\n",
       "      <td>9.62</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>35.15</td>\n",
       "      <td>62.96</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n      The international AI conference call...</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>872</td>\n",
       "      <td>281</td>\n",
       "      <td>20</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>1.561111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>141.10</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>30.11</td>\n",
       "      <td>70.99</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n      I believe that the creative writing ...</td>\n",
       "      <td>11</td>\n",
       "      <td>187</td>\n",
       "      <td>849</td>\n",
       "      <td>283</td>\n",
       "      <td>29</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.540107</td>\n",
       "      <td>1.513369</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>70.69</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.58</td>\n",
       "      <td>22.02</td>\n",
       "      <td>124.11</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fulltext  sentences  words  \\\n",
       "0  \\n\\n      The Eiffel Tower The Eiffel Tower is...         16    233   \n",
       "1  \\n\\n      The Court Green burglar arrested A 2...          7    180   \n",
       "2  \\n\\n      Thank you for giving us the opportun...         10    180   \n",
       "3  \\n\\n      The international AI conference call...         10    180   \n",
       "4  \\n\\n      I believe that the creative writing ...         11    187   \n",
       "\n",
       "   letters.all  syllables  punct  avg.sentc.length  avg.word.length  \\\n",
       "0         1116        363     32         14.562500         4.789700   \n",
       "1          866        268     18         25.714286         4.811111   \n",
       "2          861        269     20         18.000000         4.783333   \n",
       "3          872        281     20         18.000000         4.844444   \n",
       "4          849        283     29         17.000000         4.540107   \n",
       "\n",
       "   avg.syll.word  sntc.per.word   ...    Maas lgV0  MATTR  MSTTR    MTLD  \\\n",
       "0       1.557940       0.068670   ...         4.96   0.72   0.70   70.74   \n",
       "1       1.488889       0.038889   ...         5.07   0.74   0.76  107.12   \n",
       "2       1.494444       0.055556   ...         5.99   0.77   0.78  161.93   \n",
       "3       1.561111       0.055556   ...         5.49   0.77   0.81  141.10   \n",
       "4       1.513369       0.058824   ...         4.61   0.68   0.64   70.69   \n",
       "\n",
       "   Root TTR  Summer  TTR.1  Uber index  Yule's K  level1  \n",
       "0      8.98    0.88   0.59       24.30    146.62      C2  \n",
       "1      8.57    0.89   0.64       26.14    141.98      C2  \n",
       "2      9.62    0.92   0.72       35.15     62.96      C2  \n",
       "3      9.09    0.90   0.68       30.11     70.99      C2  \n",
       "4      7.97    0.87   0.58       22.02    124.11      C2  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1026
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1526221754242,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "cjUeP_yS3veA",
    "outputId": "55afba0e-d7a0-4a45-cd9a-2288b673ca67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  ‚Äî   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‚ÄòBambi‚Äô Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney‚Äôs ‚ÄúBambi‚Äù opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn‚Äôt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  ‚Äî   North Korea‚Äôs leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2           2  17285  Tyrus Wong, ‚ÄòBambi‚Äô Artist Thwarted by Racial ...   \n",
       "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "\n",
       "      publication                         author        date    year  month  \\\n",
       "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
       "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
       "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
       "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
       "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
       "\n",
       "   url                                            content  \n",
       "0  NaN  WASHINGTON  ‚Äî   Congressional Republicans have...  \n",
       "1  NaN  After the bullet shells get counted, the blood...  \n",
       "2  NaN  When Walt Disney‚Äôs ‚ÄúBambi‚Äù opened in 1942, cri...  \n",
       "3  NaN  Death may be the great equalizer, but it isn‚Äôt...  \n",
       "4  NaN  SEOUL, South Korea  ‚Äî   North Korea‚Äôs leader, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1526221425703,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "2s3hOz_53veQ",
    "outputId": "22897968-5d2e-4751-c9a4-b716da1c1da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      The Eiffel Tower The Eiffel Tower is a symbol of domination of man over steel. It also symbolizes the great maturity of architecture. Its message resonates not only in France but throughout the whole world. With opportunity of the Universal Exhibition which celebrates the 1789 century revolution, the resurgent republic wanted to make a great shot. It launched a contest in the Official Journal engineers putting the challenge to raise 'in the Champ-de-Mars an iron tower with a square base, 125 meters wide and 300 meters high.&quot; The project was won and built by Gustave Eiffel for the Universal Exhibition of 1889. Everyone has once dreamed visiting Paris and is really amazing tower. Situated in the 15th Paris district, it is now the most visited paid monument in the world, with 6,893,000 visitors in 2007. We invite you to discover some of the secrets of the &quot;Iron Lady&quot;. Its an international place where you can meet the whole world. Its absolutely wonderful to see how French people are open-minded, how they like welcoming tourists visiting their country, how they are proud to share with other people a part of their living style. You can visit and go to restaurant in the same place. You can also discover the French history and buy memories on French history over centuries. To me the tower not symbolize our past but the footprint of French greatness.\n",
      "\n",
      "\n",
      "1    After the bullet shells get counted, the blood...\n",
      "1    In Norse mythology, humans and our world were ...\n",
      "1    Copies of William Shakespeare‚Äôs first four boo...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset.loc[0, 'fulltext'])\n",
    "print(dataset1.loc[1, 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York Times  :  7803\n",
      "Breitbart  :  23781\n",
      "CNN  :  11488\n",
      "Business Insider  :  6757\n",
      "Atlantic  :  7179\n",
      "Fox News  :  4354\n",
      "Talking Points Memo  :  5214\n",
      "Buzzfeed News  :  4854\n",
      "National Review  :  6203\n",
      "New York Post  :  17493\n",
      "Guardian  :  8681\n",
      "NPR  :  11992\n",
      "Reuters  :  10710\n",
      "Vox  :  4947\n",
      "Washington Post  :  11114\n"
     ]
    }
   ],
   "source": [
    "for i in dataset1['publication'].unique():\n",
    "    print(i, ' : ', (dataset1['publication'] == i).values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardian  :  8000\n"
     ]
    }
   ],
   "source": [
    "texts_news = dataset1[dataset1['publication'] == 'Guardian']\n",
    "texts_news = texts_news.sample(8000, random_state=42)\n",
    "for i in texts_news['publication'].unique():\n",
    "    print(i, ' : ', (texts_news['publication'] == i).values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On racourcit les textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "NB_MAX_WORDS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "Attention: texte vide: 2194\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "Attention: texte vide: 3532\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "Attention: texte vide: 4018\n",
      "4100\n",
      "Attention: texte vide: 4196\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "Attention: texte vide: 4472\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "Attention: texte vide: 5624\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "Attention: texte vide: 6085\n",
      "Attention: texte vide: 6094\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "Attention: texte vide: 6964\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      " ‚Äú USA Kills Yemeni People ‚Äù screams graffiti plastered on walls in Yemen ‚Äô s capital Sana ‚Äô a . The Yemeni people who have been on the receiving end of US bombs dropped by Saudi pilots know all too well that the United States is complicit in their suffering . The intense sentiment in Yemen should be a call for Americans : if you don ‚Äô t care about the millions of suffering Yemenis , you might think about the future blowback . Two US Senators , the Republican Rand Paul and the Democrat Chris Murphy , understand full well the implications and have been trying to halt the weapons sales . ‚Äú The United States has no business supporting a war that has only served to embolden our terrorist enemies , exacerbate a humanitarian crisis , and incite fear and anger among the Yemeni people toward the United States . This will come back to haunt us , ‚Äù warned Murphy . Unfortunately , the Trump administration and the majority of US senators have failed to heed their call . On 13 June , their resolution to stop the Saudi sale of munitions was narrowly defeated by a vote . The vote broke down mainly along party lines , with four Republicans and five Democrats breaking ranks . It also broke down along another divide : peace and humanitarian aid groups v the Trump administration , lobbyists for the Saudi government and the weapons industry . Paul , an Republican pushing the resolution , railed against the senators who were more concerned about the jobs the weapons manufacturers could generate than the lives of Yemeni children .\n",
      " Bob Dylan has delivered his Nobel lecture , the only requirement to claim the money that comes with his prize for literature , the Swedish Academy confirmed on Monday . ‚Äú The speech is extraordinary and , as one might expect , eloquent . Now that the lecture has been delivered , the Dylan adventure is coming to a close , ‚Äù Sara Danius , the permanent secretary of the Swedish Academy , which awards the prize , wrote in a blog post . In the speech , sent to the academy with an audio link in which Dylan reads it aloud , the enigmatic rock star reflects on the possible links between his lyrics and literature . ‚Äú When I first received this Nobel prize for literature , I got to wondering exactly how my songs related to literature , ‚Äù Dylan said . He then cited musicians who inspired him ‚Äî including Buddy Holly , whose music ‚Äú changed my life ‚Äù and made him want to write songs when he was a teenager ‚Äî and the classic novels that made a big impression on him , including Moby Dick , All Quiet on the Western Front and The Odyssey . Dylan is the first songwriter to win the prestigious Nobel prize for literature . The lecture can take nearly any form ‚Äî including a short speech , a performance , a video broadcast or even a song ‚Äî and must be held within six months of 10 December , the date of the Nobel prize ceremony and the anniversary of the death of the prize ‚Äô s founder Alfred Nobel . Dylan will be able to claim the 8m kronor ( ‚Ç¨819 , 000 $ 923 , 000 ) that comes with the prize .\n"
     ]
    }
   ],
   "source": [
    "#si on a des textes trop longs (articles de journaux) on en enl√®ve des mots jusqu'√† un signe de ponctuation\n",
    "for i in range(texts_news['content'].shape[0]):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    tokens = nltk.word_tokenize(texts_news['content'].iloc[i])\n",
    "    while (len(tokens) > 0) and not((len(tokens) <= NB_MAX_WORDS) and (tokens[-1] in [\"?\", \"!\", \".\"])):\n",
    "        tokens = tokens[:-1]\n",
    "        if (len(tokens) <= 0):\n",
    "            print(\"Attention: texte vide:\", i)\n",
    "    #print(len(tokens))\n",
    "    temp = \"\"\n",
    "    for token in tokens:\n",
    "        temp = temp + \" \" + token\n",
    "    texts_news['content'].iloc[i] = temp\n",
    "print(texts_news['content'].iloc[0])\n",
    "print(texts_news['content'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 535,
     "status": "error",
     "timestamp": 1526222189959,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "arPdFT_Y3vee",
    "outputId": "954ae5b9-97e6-46bb-9c0b-c1aed6356d9a"
   },
   "outputs": [],
   "source": [
    "#min = dataset[dataset['level1']=='C2']['fulltext'].apply(len).min()\n",
    "#max = dataset[dataset['level1']=='C2']['fulltext'].apply(len).max()\n",
    "#dataset1 = dataset1[dataset1['content'].apply(len).between(min, max)]\n",
    "#texts_news = dataset1.sample(10000, random_state=42)\n",
    "#for i in texts_news['publication'].unique():\n",
    "#    print(i, ' : ', (texts_news['publication'] == i).values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sk4texZ3ve6"
   },
   "source": [
    "# Cr√©ation de 3 ensembles: entrainement, validation et test (sans les textes des journaux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S√©paration [entrainement+validation] [test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GOIl7usR3ve8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.2\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1526162862814,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "52J__gyD3vfE",
    "outputId": "35965494-0e8d-4ae0-bef2-e00bc349c5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21848, 60)\n",
      "(5462, 60)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=test_size, random_state=random_state, shuffle=True, stratify=dataset.loc[:,'level1'])\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1526162869934,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "O24h2s3j3vfM",
    "outputId": "75e763bb-a1ef-4948-fecd-6d111b614eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17424    \\n\\n      Hello, Why don't you buy the orange ...\n",
      "18934    \\n\\n      Good evening, how are you ? I'm fine...\n",
      "4305     \\n\\n      CAREER PLAN Name : Jean-Philippe BLA...\n",
      "13039    \\n\\n      Hi My favortite hobby with my famill...\n",
      "13124    \\n\\n      My great job, but... I am a manager ...\n",
      "Name: fulltext, dtype: object\n",
      "(21848,)\n",
      "(21848,)\n"
     ]
    }
   ],
   "source": [
    "y = train['level1']\n",
    "X = train['fulltext']\n",
    "\n",
    "print(X.head())\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2338
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1526162895388,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "yquY4-633vgw",
    "outputId": "12038956-39d7-42cc-eeb2-dab49c25b64c"
   },
   "outputs": [],
   "source": [
    "y = np.array(y.replace({\"A1\": 0, \"A2\" : 1, \"B1\" : 2, \"B2\" : 3, \"C1\" : 4, \"C2\" : 5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S√©paration de entrainement et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17424    \\n\\n      Hello, Why don't you buy the orange ...\n",
      "18934    \\n\\n      Good evening, how are you ? I'm fine...\n",
      "4305     \\n\\n      CAREER PLAN Name : Jean-Philippe BLA...\n",
      "13039    \\n\\n      Hi My favortite hobby with my famill...\n",
      "13124    \\n\\n      My great job, but... I am a manager ...\n",
      "Name: fulltext, dtype: object\n",
      "(15293,)\n",
      "(15293,)\n",
      "(6555,)\n",
      "(6555,)\n"
     ]
    }
   ],
   "source": [
    "training_size = 0.7\n",
    "\n",
    "X_train = X[0:int(X.shape[0]*training_size)]\n",
    "y_train = y[0:int(y.shape[0]*training_size)]\n",
    "\n",
    "X_val = X[int(X.shape[0]*training_size):]\n",
    "y_val = y[int(y.shape[0]*training_size):]\n",
    "\n",
    "print(X_train.head())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faO1EzDh3vhq"
   },
   "source": [
    "# Ajout des textes des journaux √† l'ensemble d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1526162854194,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "eE5c8ejD3vem",
    "outputId": "2827363e-d894-474b-e2ca-9eadca297d65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\n\\n      Hello, Why don't you buy the orange ...\n",
       "1        \\n\\n      Good evening, how are you ? I'm fine...\n",
       "2        \\n\\n      CAREER PLAN Name : Jean-Philippe BLA...\n",
       "3        \\n\\n      Hi My favortite hobby with my famill...\n",
       "4        \\n\\n      My great job, but... I am a manager ...\n",
       "5        \\n\\n      Here is the story of a friend of min...\n",
       "6        \\n\\n      I Love to travel. I've visited Thail...\n",
       "7        \\n\\n      While I was studying the Law, I had ...\n",
       "8        \\n\\n      Hello, My name's Erwan. I'm in great...\n",
       "9        \\n\\n      John learn that Isabella should to g...\n",
       "10       \\n\\n      To whom it may concern: I am writing...\n",
       "11       \\n\\n      Hello,I'm really sorry to tell you t...\n",
       "12       \\n\\n      My name's Dominique, I am buyer, I w...\n",
       "13       \\n\\n      Today at 6.30 p.m I'm going to a lec...\n",
       "14       \\n\\n      HI,sorry the weather is horrible and...\n",
       "15       \\n\\n      For some aches, home remedies could ...\n",
       "16       \\n\\n      HelloFor my birthday I'd like to do ...\n",
       "17       \\n\\n      Dear Sir or Madam, My name is Adelin...\n",
       "18       \\n\\n      Hi. The online catalog has : -sneake...\n",
       "19       \\n\\n      Dear Mom and Dad, In September, I wi...\n",
       "20       \\n\\n      In Santa Monica today it's going to ...\n",
       "21       \\n\\n      I think the president board prepared...\n",
       "22       \\n\\n      Hi Mom and Dad,Today we are in Santa...\n",
       "23       \\n\\n      Date : Monday 11th Time : 9.30 am Fo...\n",
       "24       \\n\\n      I work in an office. I sit an my des...\n",
       "25       \\n\\n      Name: Mehdy. Age: eight and half. Wo...\n",
       "26       \\n\\n      My name's Brigitte. I'm 64 years old...\n",
       "27       \\n\\n      Dear Mr Gibson,Thanks for your answe...\n",
       "28       \\n\\n      Dear Ms Thomas, There are thirty pen...\n",
       "29       \\n\\n      Hi Mum and Dad,I'm in Santa Monica f...\n",
       "                               ...                        \n",
       "23263     ‚Äú ‚Äù and ‚Äú fake news ‚Äù have been etched , perh...\n",
       "23264     Florida librarians have come up with a unique...\n",
       "23265     As dawn breaks over the hungover heads of Bla...\n",
       "23266     In my exploration of ‚Äú fake news ‚Äù I ‚Äô ve fou...\n",
       "23267     Samantha Bee has criticized Donald Trump ‚Äô s ...\n",
       "23268     Mariah Carey has issued a partial explanation...\n",
       "23269     By ordering a zealous crackdown on crime and ...\n",
       "23270     Arab book fairs are like a giant travelling c...\n",
       "23271     Does pop culture science fiction merely refle...\n",
       "23272     Spoiler alert : this blog is for Twin Peaks v...\n",
       "23273     After months of controversy including a turf ...\n",
       "23274     Google has been forced to open up Android to ...\n",
       "23275     The Tesla chief executive , Elon Musk , has u...\n",
       "23276     The US has said it will work with the Philipp...\n",
       "23277     In this week ‚Äô s episode of Chips with Everyt...\n",
       "23278     A plebiscite in the US ‚Äô s oldest and largest...\n",
       "23279     The resurgence of Fast and the Furious from t...\n",
       "23280     Donald Trump appears to be backing away from ...\n",
       "23281     Before long , Santiago could be a city full o...\n",
       "23282     SpaceX failed to land a Falcon 9 rocket on a ...\n",
       "23283     The plight of child refugees is at the heart ...\n",
       "23284     Laden with nets and reeking of rotten fish , ...\n",
       "23285     Tom Brady ‚Äô s Super Bowl jersey went missing ...\n",
       "23286     Hundreds of churches in the US have said they...\n",
       "23287     Amazon ‚Äô s next step in its global domination...\n",
       "23288     The Trump administration has so far attempted...\n",
       "23289     Gabby Douglas stood beneath the Rio Olympic A...\n",
       "23290     A teenager has been charged with murder after...\n",
       "23291     In a country where at times it seems that the...\n",
       "23292     A former employee at the Royal Canadian Mint ...\n",
       "Length: 23293, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on concat√®ne les deux dataFrames\n",
    "df = texts_news['content']\n",
    "df.columns = ['fulltext']\n",
    "X_train = X_train.append(df, ignore_index=True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23293,)\n"
     ]
    }
   ],
   "source": [
    "y_texts_news = [5] * texts_news.shape[0]\n",
    "y_train = np.concatenate((y_train, y_texts_news))\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cr√©ation des repr√©sentations matricielles des textes (Word2Vec) et enregistrement dans des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEN7yRfd3vhs"
   },
   "source": [
    "Repr√©sentation des donn√©es:\n",
    "\n",
    "Word2Vec:\n",
    "- http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "- https://www.tensorflow.org/hub/modules/text\n",
    "- https://www.tensorflow.org/hub/modules/google/Wiki-words-250/1\n",
    "- http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXWUW4Ly3vhs"
   },
   "source": [
    "T√©l√©charger GoogleNews-vectors-negative300.bin √† https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9TGc1xQ03vhu"
   },
   "outputs": [],
   "source": [
    "!pip install -q gensim\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('wordToVec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "__3CgXmg3viG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjcUtpDy3viK"
   },
   "source": [
    "On transforme chaque texte en une matrice avec des mots sous forme de vecteurs de taille 300. Les matrices sont compl√©t√©es avec des vecteurs nuls afin qu'elles aient toutes la m√™me dimension. Les matrices sont stock√©es sous forme de matrices creuses (scipy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entr√©e:\n",
    "- X: ensemble de textes\n",
    "\n",
    "Sortie:\n",
    "- texts_matrices: matrices calcul√©es avec Word2Vec\n",
    "- size_texts: taille r√©elle de chaque matrice (utilis√© par tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33132,
     "status": "ok",
     "timestamp": 1526163024016,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "Vz3EwhgE3viM",
    "outputId": "12118199-1404-45c0-d4ba-145124d0f35b"
   },
   "outputs": [],
   "source": [
    "def Word2Vec(X):\n",
    "    texts_matrices = []\n",
    "    total_nb_tokens = 0\n",
    "    total_nb_unknown = 0\n",
    "    avg_nb_unknown = 0\n",
    "    for row in X:\n",
    "        #print(\"===TEXT===\")\n",
    "        #print(row)\n",
    "        tokens = nltk.word_tokenize(row)\n",
    "        text_matrix = []\n",
    "        nb_unknown = 0\n",
    "        for word in tokens:\n",
    "            try:\n",
    "                word_emb = word_vectors.wv[word]\n",
    "                text_matrix.append(word_emb)\n",
    "                #print(\"Known word:\", word)\n",
    "            except:\n",
    "                nb_unknown = nb_unknown+1\n",
    "                #print(\"Unknown word:\", word)\n",
    "        if len(text_matrix)==0:\n",
    "            text_matrix = np.zeros(texts_matrices[0].shape[1]).reshape(1,-1)\n",
    "        texts_matrices.append(np.array(text_matrix))\n",
    "\n",
    "        total_nb_tokens = total_nb_tokens + len(tokens)\n",
    "        total_nb_unknown = total_nb_unknown + nb_unknown\n",
    "    texts_matrices = np.array(texts_matrices)\n",
    "    avg_nb_unknown = total_nb_unknown / total_nb_tokens\n",
    "    print(\"texts_matrices.shape=\", texts_matrices.shape)\n",
    "    print(\"Nombre moyens de mots inconnus (par exemple la ponctuation)=\", avg_nb_unknown)\n",
    "    \n",
    "    # A MODIFIER (prendre en compte tous les textes...)\n",
    "    nb_words_max = 418\n",
    "    \n",
    "    #for i in range(texts_matrices.shape[0]):\n",
    "    #    nb_words = texts_matrices[i].shape[0]\n",
    "    #    if nb_words > nb_words_max:\n",
    "    #        nb_words_max = nb_words\n",
    "    #print(\"Nombre de lignes de la plus grande matrice=\", nb_words_max)\n",
    "    \n",
    "    size_texts = np.zeros(texts_matrices.shape[0])\n",
    "    new_line = np.zeros((1, texts_matrices[1].shape[1]))\n",
    "    for i in range(texts_matrices.shape[0]):\n",
    "        if i%100==0:\n",
    "            print(\"i=\", i)\n",
    "        size_texts[i] = texts_matrices[i].shape[0]\n",
    "        #on compl√®te les textes avec des 0\n",
    "        while texts_matrices[i].shape[0] < nb_words_max:\n",
    "            texts_matrices[i] = np.append(texts_matrices[i], new_line, axis=0)\n",
    "        \n",
    "        texts_matrices[i] = scipy.sparse.csr_matrix(texts_matrices[i])\n",
    "        #np.sort(size_texts)[-100:]\n",
    "    \n",
    "    return texts_matrices, size_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts_matrices.shape= (23293,)\n",
      "Nombre moyens de mots inconnus (par exemple la ponctuation)= 0.23581647455857627\n",
      "i= 0\n",
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n",
      "i= 6600\n",
      "i= 6700\n",
      "i= 6800\n",
      "i= 6900\n",
      "i= 7000\n",
      "i= 7100\n",
      "i= 7200\n",
      "i= 7300\n",
      "i= 7400\n",
      "i= 7500\n",
      "i= 7600\n",
      "i= 7700\n",
      "i= 7800\n",
      "i= 7900\n",
      "i= 8000\n",
      "i= 8100\n",
      "i= 8200\n",
      "i= 8300\n",
      "i= 8400\n",
      "i= 8500\n",
      "i= 8600\n",
      "i= 8700\n",
      "i= 8800\n",
      "i= 8900\n",
      "i= 9000\n",
      "i= 9100\n",
      "i= 9200\n",
      "i= 9300\n",
      "i= 9400\n",
      "i= 9500\n",
      "i= 9600\n",
      "i= 9700\n",
      "i= 9800\n",
      "i= 9900\n",
      "i= 10000\n",
      "i= 10100\n",
      "i= 10200\n",
      "i= 10300\n",
      "i= 10400\n",
      "i= 10500\n",
      "i= 10600\n",
      "i= 10700\n",
      "i= 10800\n",
      "i= 10900\n",
      "i= 11000\n",
      "i= 11100\n",
      "i= 11200\n",
      "i= 11300\n",
      "i= 11400\n",
      "i= 11500\n",
      "i= 11600\n",
      "i= 11700\n",
      "i= 11800\n",
      "i= 11900\n",
      "i= 12000\n",
      "i= 12100\n",
      "i= 12200\n",
      "i= 12300\n",
      "i= 12400\n",
      "i= 12500\n",
      "i= 12600\n",
      "i= 12700\n",
      "i= 12800\n",
      "i= 12900\n",
      "i= 13000\n",
      "i= 13100\n",
      "i= 13200\n",
      "i= 13300\n",
      "i= 13400\n",
      "i= 13500\n",
      "i= 13600\n",
      "i= 13700\n",
      "i= 13800\n",
      "i= 13900\n",
      "i= 14000\n",
      "i= 14100\n",
      "i= 14200\n",
      "i= 14300\n",
      "i= 14400\n",
      "i= 14500\n",
      "i= 14600\n",
      "i= 14700\n",
      "i= 14800\n",
      "i= 14900\n",
      "i= 15000\n",
      "i= 15100\n",
      "i= 15200\n",
      "i= 15300\n",
      "i= 15400\n",
      "i= 15500\n",
      "i= 15600\n",
      "i= 15700\n",
      "i= 15800\n",
      "i= 15900\n",
      "i= 16000\n",
      "i= 16100\n",
      "i= 16200\n",
      "i= 16300\n",
      "i= 16400\n",
      "i= 16500\n",
      "i= 16600\n",
      "i= 16700\n",
      "i= 16800\n",
      "i= 16900\n",
      "i= 17000\n",
      "i= 17100\n",
      "i= 17200\n",
      "i= 17300\n",
      "i= 17400\n",
      "i= 17500\n",
      "i= 17600\n",
      "i= 17700\n",
      "i= 17800\n",
      "i= 17900\n",
      "i= 18000\n",
      "i= 18100\n",
      "i= 18200\n",
      "i= 18300\n",
      "i= 18400\n",
      "i= 18500\n",
      "i= 18600\n",
      "i= 18700\n",
      "i= 18800\n",
      "i= 18900\n",
      "i= 19000\n",
      "i= 19100\n",
      "i= 19200\n",
      "i= 19300\n",
      "i= 19400\n",
      "i= 19500\n",
      "i= 19600\n",
      "i= 19700\n",
      "i= 19800\n",
      "i= 19900\n",
      "i= 20000\n",
      "i= 20100\n",
      "i= 20200\n",
      "i= 20300\n",
      "i= 20400\n",
      "i= 20500\n",
      "i= 20600\n",
      "i= 20700\n",
      "i= 20800\n",
      "i= 20900\n",
      "i= 21000\n",
      "i= 21100\n",
      "i= 21200\n",
      "i= 21300\n",
      "i= 21400\n",
      "i= 21500\n",
      "i= 21600\n",
      "i= 21700\n",
      "i= 21800\n",
      "i= 21900\n",
      "i= 22000\n",
      "i= 22100\n",
      "i= 22200\n",
      "i= 22300\n",
      "i= 22400\n",
      "i= 22500\n",
      "i= 22600\n",
      "i= 22700\n",
      "i= 22800\n",
      "i= 22900\n",
      "i= 23000\n",
      "i= 23100\n",
      "i= 23200\n",
      "texts_matrices.shape= (6555,)\n",
      "Nombre moyens de mots inconnus (par exemple la ponctuation)= 0.24157770705185488\n",
      "i= 0\n",
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n"
     ]
    }
   ],
   "source": [
    "X_train_matrices, size_texts_train = Word2Vec(X_train)\n",
    "X_val_matrices, size_texts_val = Word2Vec(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BzybUaY_3viW"
   },
   "source": [
    "Sauvegarde des textes sous forme de matrices et sauvegarde du vecteur comptenant la taille initiale des textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wort7kt83viU"
   },
   "outputs": [],
   "source": [
    "def save(array, filename):\n",
    "    print(\"Save in\", filename)\n",
    "    for i in range(array.shape[0]):\n",
    "        if i%100==0 and i > 0:\n",
    "            print(\"i=\", i)\n",
    "        size_label = len(str(array.shape[0]))\n",
    "        label = str(i)\n",
    "        while len(label)<size_label:\n",
    "            label = \"0\"+label\n",
    "        scipy.sparse.save_npz(matrix=array[i], file=filename+\"_\"+label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1010
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 756,
     "status": "error",
     "timestamp": 1526157701254,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "zLaqDk6_3viY",
    "outputId": "6eb613ac-940b-47b3-93bb-d8362710825c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save in ./texts_matrices_with_news/train/matrix\n",
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n",
      "i= 6600\n",
      "i= 6700\n",
      "i= 6800\n",
      "i= 6900\n",
      "i= 7000\n",
      "i= 7100\n",
      "i= 7200\n",
      "i= 7300\n",
      "i= 7400\n",
      "i= 7500\n",
      "i= 7600\n",
      "i= 7700\n",
      "i= 7800\n",
      "i= 7900\n",
      "i= 8000\n",
      "i= 8100\n",
      "i= 8200\n",
      "i= 8300\n",
      "i= 8400\n",
      "i= 8500\n",
      "i= 8600\n",
      "i= 8700\n",
      "i= 8800\n",
      "i= 8900\n",
      "i= 9000\n",
      "i= 9100\n",
      "i= 9200\n",
      "i= 9300\n",
      "i= 9400\n",
      "i= 9500\n",
      "i= 9600\n",
      "i= 9700\n",
      "i= 9800\n",
      "i= 9900\n",
      "i= 10000\n",
      "i= 10100\n",
      "i= 10200\n",
      "i= 10300\n",
      "i= 10400\n",
      "i= 10500\n",
      "i= 10600\n",
      "i= 10700\n",
      "i= 10800\n",
      "i= 10900\n",
      "i= 11000\n",
      "i= 11100\n",
      "i= 11200\n",
      "i= 11300\n",
      "i= 11400\n",
      "i= 11500\n",
      "i= 11600\n",
      "i= 11700\n",
      "i= 11800\n",
      "i= 11900\n",
      "i= 12000\n",
      "i= 12100\n",
      "i= 12200\n",
      "i= 12300\n",
      "i= 12400\n",
      "i= 12500\n",
      "i= 12600\n",
      "i= 12700\n",
      "i= 12800\n",
      "i= 12900\n",
      "i= 13000\n",
      "i= 13100\n",
      "i= 13200\n",
      "i= 13300\n",
      "i= 13400\n",
      "i= 13500\n",
      "i= 13600\n",
      "i= 13700\n",
      "i= 13800\n",
      "i= 13900\n",
      "i= 14000\n",
      "i= 14100\n",
      "i= 14200\n",
      "i= 14300\n",
      "i= 14400\n",
      "i= 14500\n",
      "i= 14600\n",
      "i= 14700\n",
      "i= 14800\n",
      "i= 14900\n",
      "i= 15000\n",
      "i= 15100\n",
      "i= 15200\n",
      "i= 15300\n",
      "i= 15400\n",
      "i= 15500\n",
      "i= 15600\n",
      "i= 15700\n",
      "i= 15800\n",
      "i= 15900\n",
      "i= 16000\n",
      "i= 16100\n",
      "i= 16200\n",
      "i= 16300\n",
      "i= 16400\n",
      "i= 16500\n",
      "i= 16600\n",
      "i= 16700\n",
      "i= 16800\n",
      "i= 16900\n",
      "i= 17000\n",
      "i= 17100\n",
      "i= 17200\n",
      "i= 17300\n",
      "i= 17400\n",
      "i= 17500\n",
      "i= 17600\n",
      "i= 17700\n",
      "i= 17800\n",
      "i= 17900\n",
      "i= 18000\n",
      "i= 18100\n",
      "i= 18200\n",
      "i= 18300\n",
      "i= 18400\n",
      "i= 18500\n",
      "i= 18600\n",
      "i= 18700\n",
      "i= 18800\n",
      "i= 18900\n",
      "i= 19000\n",
      "i= 19100\n",
      "i= 19200\n",
      "i= 19300\n",
      "i= 19400\n",
      "i= 19500\n",
      "i= 19600\n",
      "i= 19700\n",
      "i= 19800\n",
      "i= 19900\n",
      "i= 20000\n",
      "i= 20100\n",
      "i= 20200\n",
      "i= 20300\n",
      "i= 20400\n",
      "i= 20500\n",
      "i= 20600\n",
      "i= 20700\n",
      "i= 20800\n",
      "i= 20900\n",
      "i= 21000\n",
      "i= 21100\n",
      "i= 21200\n",
      "i= 21300\n",
      "i= 21400\n",
      "i= 21500\n",
      "i= 21600\n",
      "i= 21700\n",
      "i= 21800\n",
      "i= 21900\n",
      "i= 22000\n",
      "i= 22100\n",
      "i= 22200\n",
      "i= 22300\n",
      "i= 22400\n",
      "i= 22500\n",
      "i= 22600\n",
      "i= 22700\n",
      "i= 22800\n",
      "i= 22900\n",
      "i= 23000\n",
      "i= 23100\n",
      "i= 23200\n",
      "Save in ./texts_matrices_with_news/val/matrix\n",
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n"
     ]
    }
   ],
   "source": [
    "directory = \"texts_matrices_with_news\"\n",
    "directory2 = \"size_texts_with_news\"\n",
    "\n",
    "filename = \"./\" + directory + \"/train/matrix\"\n",
    "save(X_train_matrices, filename)\n",
    "\n",
    "filename = \"./\" + directory2 + \"/train\"\n",
    "np.save(filename, size_texts_train, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "filename = \"./\" + directory + \"/val/matrix\"\n",
    "save(X_val_matrices, filename)\n",
    "\n",
    "filename = \"./\" + directory2 + \"/val\"\n",
    "np.save(filename, size_texts_val, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np.array(y_train).reshape(-1,)\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde des y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory3 = \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./\" + directory3 + \"/train\"\n",
    "np.save(filename, y_train, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "filename = \"./\" + directory3 + \"/val\"\n",
    "np.save(filename, y_val, allow_pickle=True, fix_imports=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SqMorIoX3vfW",
    "MXZkKdYg3vfW",
    "DStYdHy53vfq",
    "grbQj7Jq3vgk",
    "gdEtlOon3vgu",
    "SPTEYAHB3vgu",
    "faO1EzDh3vhq",
    "WPw_A2ta3vim",
    "cWgDYp7H3vjO",
    "TW2KuS0Q3vkK"
   ],
   "default_view": {},
   "name": "preparation_donnees_premier_RNN .ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
