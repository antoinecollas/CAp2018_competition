{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzxJNqHi3vdY"
   },
   "source": [
    "# Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3w4l-a5M3vdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53191,
     "status": "ok",
     "timestamp": 1526220903624,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "urpwuZz33vdm",
    "outputId": "74eb6038-8f3a-448c-a431-2b01fadc5f7d"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/train_cap2018.csv')\n",
    "dataset1 = pd.read_csv('data/articles1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1526220904153,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "GWkU0ZCM3vdu",
    "outputId": "1601f797-8599-4569-f9c2-cf6db9a90ee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27310, 60)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1526158471398,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "1KDetbuH3vey",
    "outputId": "4fbcf80b-8c4b-4967-e77a-c70e18af62c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2  :  50\n",
      "C1  :  491\n",
      "B2  :  2337\n",
      "B1  :  5383\n",
      "A2  :  7688\n",
      "A1  :  11361\n"
     ]
    }
   ],
   "source": [
    "for i in dataset['level1'].unique():\n",
    "    print(i, ' : ', (dataset['level1'] == i).values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1526221374891,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "SsgrrYt-3vd6",
    "outputId": "9f056c04-db18-4e8d-a89b-47cc149a1988"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulltext</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>letters.all</th>\n",
       "      <th>syllables</th>\n",
       "      <th>punct</th>\n",
       "      <th>avg.sentc.length</th>\n",
       "      <th>avg.word.length</th>\n",
       "      <th>avg.syll.word</th>\n",
       "      <th>sntc.per.word</th>\n",
       "      <th>...</th>\n",
       "      <th>Maas lgV0</th>\n",
       "      <th>MATTR</th>\n",
       "      <th>MSTTR</th>\n",
       "      <th>MTLD</th>\n",
       "      <th>Root TTR</th>\n",
       "      <th>Summer</th>\n",
       "      <th>TTR.1</th>\n",
       "      <th>Uber index</th>\n",
       "      <th>Yule's K</th>\n",
       "      <th>level1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n      The Eiffel Tower The Eiffel Tower is...</td>\n",
       "      <td>16</td>\n",
       "      <td>233</td>\n",
       "      <td>1116</td>\n",
       "      <td>363</td>\n",
       "      <td>32</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>4.789700</td>\n",
       "      <td>1.557940</td>\n",
       "      <td>0.068670</td>\n",
       "      <td>...</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>70.74</td>\n",
       "      <td>8.98</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.59</td>\n",
       "      <td>24.30</td>\n",
       "      <td>146.62</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n      The Court Green burglar arrested A 2...</td>\n",
       "      <td>7</td>\n",
       "      <td>180</td>\n",
       "      <td>866</td>\n",
       "      <td>268</td>\n",
       "      <td>18</td>\n",
       "      <td>25.714286</td>\n",
       "      <td>4.811111</td>\n",
       "      <td>1.488889</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>...</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>107.12</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.64</td>\n",
       "      <td>26.14</td>\n",
       "      <td>141.98</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n      Thank you for giving us the opportun...</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>861</td>\n",
       "      <td>269</td>\n",
       "      <td>20</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.783333</td>\n",
       "      <td>1.494444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>161.93</td>\n",
       "      <td>9.62</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>35.15</td>\n",
       "      <td>62.96</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n      The international AI conference call...</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>872</td>\n",
       "      <td>281</td>\n",
       "      <td>20</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>1.561111</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>141.10</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>30.11</td>\n",
       "      <td>70.99</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n      I believe that the creative writing ...</td>\n",
       "      <td>11</td>\n",
       "      <td>187</td>\n",
       "      <td>849</td>\n",
       "      <td>283</td>\n",
       "      <td>29</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.540107</td>\n",
       "      <td>1.513369</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>70.69</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.58</td>\n",
       "      <td>22.02</td>\n",
       "      <td>124.11</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fulltext  sentences  words  \\\n",
       "0  \\n\\n      The Eiffel Tower The Eiffel Tower is...         16    233   \n",
       "1  \\n\\n      The Court Green burglar arrested A 2...          7    180   \n",
       "2  \\n\\n      Thank you for giving us the opportun...         10    180   \n",
       "3  \\n\\n      The international AI conference call...         10    180   \n",
       "4  \\n\\n      I believe that the creative writing ...         11    187   \n",
       "\n",
       "   letters.all  syllables  punct  avg.sentc.length  avg.word.length  \\\n",
       "0         1116        363     32         14.562500         4.789700   \n",
       "1          866        268     18         25.714286         4.811111   \n",
       "2          861        269     20         18.000000         4.783333   \n",
       "3          872        281     20         18.000000         4.844444   \n",
       "4          849        283     29         17.000000         4.540107   \n",
       "\n",
       "   avg.syll.word  sntc.per.word   ...    Maas lgV0  MATTR  MSTTR    MTLD  \\\n",
       "0       1.557940       0.068670   ...         4.96   0.72   0.70   70.74   \n",
       "1       1.488889       0.038889   ...         5.07   0.74   0.76  107.12   \n",
       "2       1.494444       0.055556   ...         5.99   0.77   0.78  161.93   \n",
       "3       1.561111       0.055556   ...         5.49   0.77   0.81  141.10   \n",
       "4       1.513369       0.058824   ...         4.61   0.68   0.64   70.69   \n",
       "\n",
       "   Root TTR  Summer  TTR.1  Uber index  Yule's K  level1  \n",
       "0      8.98    0.88   0.59       24.30    146.62      C2  \n",
       "1      8.57    0.89   0.64       26.14    141.98      C2  \n",
       "2      9.62    0.92   0.72       35.15     62.96      C2  \n",
       "3      9.09    0.90   0.68       30.11     70.99      C2  \n",
       "4      7.97    0.87   0.58       22.02    124.11      C2  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1026
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1526221754242,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "cjUeP_yS3veA",
    "outputId": "55afba0e-d7a0-4a45-cd9a-2288b673ca67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2           2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "\n",
       "      publication                         author        date    year  month  \\\n",
       "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
       "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
       "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
       "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
       "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
       "\n",
       "   url                                            content  \n",
       "0  NaN  WASHINGTON  —   Congressional Republicans have...  \n",
       "1  NaN  After the bullet shells get counted, the blood...  \n",
       "2  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3  NaN  Death may be the great equalizer, but it isn’t...  \n",
       "4  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1526221425703,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "2s3hOz_53veQ",
    "outputId": "22897968-5d2e-4751-c9a4-b716da1c1da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      The Eiffel Tower The Eiffel Tower is a symbol of domination of man over steel. It also symbolizes the great maturity of architecture. Its message resonates not only in France but throughout the whole world. With opportunity of the Universal Exhibition which celebrates the 1789 century revolution, the resurgent republic wanted to make a great shot. It launched a contest in the Official Journal engineers putting the challenge to raise 'in the Champ-de-Mars an iron tower with a square base, 125 meters wide and 300 meters high.&quot; The project was won and built by Gustave Eiffel for the Universal Exhibition of 1889. Everyone has once dreamed visiting Paris and is really amazing tower. Situated in the 15th Paris district, it is now the most visited paid monument in the world, with 6,893,000 visitors in 2007. We invite you to discover some of the secrets of the &quot;Iron Lady&quot;. Its an international place where you can meet the whole world. Its absolutely wonderful to see how French people are open-minded, how they like welcoming tourists visiting their country, how they are proud to share with other people a part of their living style. You can visit and go to restaurant in the same place. You can also discover the French history and buy memories on French history over centuries. To me the tower not symbolize our past but the footprint of French greatness.\n",
      "\n",
      "\n",
      "WASHINGTON  —   Congressional Republicans have a new fear when it comes to their    health care lawsuit against the Obama administration: They might win. The incoming Trump administration could choose to no longer defend the executive branch against the suit, which challenges the administration’s authority to spend billions of dollars on health insurance subsidies for   and   Americans, handing House Republicans a big victory on    issues. But a sudden loss of the disputed subsidies could conceivably cause the health care program to implode, leaving millions of people without access to health insurance before Republicans have prepared a replacement. That could lead to chaos in the insurance market and spur a political backlash just as Republicans gain full control of the government. To stave off that outcome, Republicans could find themselves in the awkward position of appropriating huge sums to temporarily prop up the Obama health care law, angering conservative voters who have been demanding an end to the law for years. In another twist, Donald J. Trump’s administration, worried about preserving executive branch prerogatives, could choose to fight its Republican allies in the House on some central questions in the dispute. Eager to avoid an ugly political pileup, Republicans on Capitol Hill and the Trump transition team are gaming out how to handle the lawsuit, which, after the election, has been put in limbo until at least late February by the United States Court of Appeals for the District of Columbia Circuit. They are not yet ready to divulge their strategy. “Given that this pending litigation involves the Obama administration and Congress, it would be inappropriate to comment,” said Phillip J. Blando, a spokesman for the Trump transition effort. “Upon taking office, the Trump administration will evaluate this case and all related aspects of the Affordable Care Act. ” In a potentially   decision in 2015, Judge Rosemary M. Collyer ruled that House Republicans had the standing to sue the executive branch over a spending dispute and that the Obama administration had been distributing the health insurance subsidies, in violation of the Constitution, without approval from Congress. The Justice Department, confident that Judge Collyer’s decision would be reversed, quickly appealed, and the subsidies have remained in place during the appeal. In successfully seeking a temporary halt in the proceedings after Mr. Trump won, House Republicans last month told the court that they “and the  ’s transition team currently are discussing potential options for resolution of this matter, to take effect after the  ’s inauguration on Jan. 20, 2017. ” The suspension of the case, House lawyers said, will “provide the   and his future administration time to consider whether to continue prosecuting or to otherwise resolve this appeal. ” Republican leadership officials in the House acknowledge the possibility of “cascading effects” if the   payments, which have totaled an estimated $13 billion, are suddenly stopped. Insurers that receive the subsidies in exchange for paying    costs such as deductibles and   for eligible consumers could race to drop coverage since they would be losing money. Over all, the loss of the subsidies could destabilize the entire program and cause a lack of confidence that leads other insurers to seek a quick exit as well. Anticipating that the Trump administration might not be inclined to mount a vigorous fight against the House Republicans given the  ’s dim view of the health care law, a team of lawyers this month sought to intervene in the case on behalf of two participants in the health care program. In their request, the lawyers predicted that a deal between House Republicans and the new administration to dismiss or settle the case “will produce devastating consequences for the individuals who receive these reductions, as well as for the nation’s health insurance and health care systems generally. ” No matter what happens, House Republicans say, they want to prevail on two overarching concepts: the congressional power of the purse, and the right of Congress to sue the executive branch if it violates the Constitution regarding that spending power. House Republicans contend that Congress never appropriated the money for the subsidies, as required by the Constitution. In the suit, which was initially championed by John A. Boehner, the House speaker at the time, and later in House committee reports, Republicans asserted that the administration, desperate for the funding, had required the Treasury Department to provide it despite widespread internal skepticism that the spending was proper. The White House said that the spending was a permanent part of the law passed in 2010, and that no annual appropriation was required  —   even though the administration initially sought one. Just as important to House Republicans, Judge Collyer found that Congress had the standing to sue the White House on this issue  —   a ruling that many legal experts said was flawed  —   and they want that precedent to be set to restore congressional leverage over the executive branch. But on spending power and standing, the Trump administration may come under pressure from advocates of presidential authority to fight the House no matter their shared views on health care, since those precedents could have broad repercussions. It is a complicated set of dynamics illustrating how a quick legal victory for the House in the Trump era might come with costs that Republicans never anticipated when they took on the Obama White House.\n"
     ]
    }
   ],
   "source": [
    "print(dataset.loc[0, 'fulltext'])\n",
    "print(dataset1.loc[0, 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 535,
     "status": "error",
     "timestamp": 1526222189959,
     "user": {
      "displayName": "Antoine Collas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "103215139411431443043"
     },
     "user_tz": -120
    },
    "id": "arPdFT_Y3vee",
    "outputId": "954ae5b9-97e6-46bb-9c0b-c1aed6356d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breitbart  :  6421\n",
      "CNN  :  1389\n",
      "Business Insider  :  2053\n",
      "New York Times  :  136\n",
      "Atlantic  :  1\n"
     ]
    }
   ],
   "source": [
    "min = dataset[dataset['level1']=='C2']['fulltext'].apply(len).min()\n",
    "max = dataset[dataset['level1']=='C2']['fulltext'].apply(len).max()\n",
    "dataset1 = dataset1[dataset1['content'].apply(len).between(min, max)]\n",
    "texts_news = dataset1.sample(10000, random_state=42)\n",
    "for i in texts_news['publication'].unique():\n",
    "    print(i, ' : ', (texts_news['publication'] == i).values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sk4texZ3ve6"
   },
   "source": [
    "# Création de 3 ensembles: entrainement, validation et test (sans les textes des journaux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation [entrainement+validation] [test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GOIl7usR3ve8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.2\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1526162862814,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "52J__gyD3vfE",
    "outputId": "35965494-0e8d-4ae0-bef2-e00bc349c5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21848, 60)\n",
      "(5462, 60)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=test_size, random_state=random_state, shuffle=True, stratify=dataset.loc[:,'level1'])\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1526162869934,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "O24h2s3j3vfM",
    "outputId": "75e763bb-a1ef-4948-fecd-6d111b614eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17424    \\n\\n      Hello, Why don't you buy the orange ...\n",
      "18934    \\n\\n      Good evening, how are you ? I'm fine...\n",
      "4305     \\n\\n      CAREER PLAN Name : Jean-Philippe BLA...\n",
      "13039    \\n\\n      Hi My favortite hobby with my famill...\n",
      "13124    \\n\\n      My great job, but... I am a manager ...\n",
      "Name: fulltext, dtype: object\n",
      "(21848,)\n",
      "(21848,)\n"
     ]
    }
   ],
   "source": [
    "y = train['level1']\n",
    "X = train['fulltext']\n",
    "\n",
    "print(X.head())\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2338
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1526162895388,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "yquY4-633vgw",
    "outputId": "12038956-39d7-42cc-eeb2-dab49c25b64c"
   },
   "outputs": [],
   "source": [
    "y = np.array(y.replace({\"A1\": 0, \"A2\" : 1, \"B1\" : 2, \"B2\" : 3, \"C1\" : 4, \"C2\" : 5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation de entrainement et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17424    \\n\\n      Hello, Why don't you buy the orange ...\n",
      "18934    \\n\\n      Good evening, how are you ? I'm fine...\n",
      "4305     \\n\\n      CAREER PLAN Name : Jean-Philippe BLA...\n",
      "13039    \\n\\n      Hi My favortite hobby with my famill...\n",
      "13124    \\n\\n      My great job, but... I am a manager ...\n",
      "Name: fulltext, dtype: object\n",
      "(15293,)\n",
      "(15293,)\n",
      "(6555,)\n",
      "(6555,)\n"
     ]
    }
   ],
   "source": [
    "training_size = 0.7\n",
    "\n",
    "X_train = X[0:int(X.shape[0]*training_size)]\n",
    "y_train = y[0:int(y.shape[0]*training_size)]\n",
    "\n",
    "X_val = X[int(X.shape[0]*training_size):]\n",
    "y_val = y[int(y.shape[0]*training_size):]\n",
    "\n",
    "print(X_train.head())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faO1EzDh3vhq"
   },
   "source": [
    "# Ajout des textes des journaux à l'ensemble d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1526162854194,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "eE5c8ejD3vem",
    "outputId": "2827363e-d894-474b-e2ca-9eadca297d65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\n\\n      Hello, Why don't you buy the orange ...\n",
       "1        \\n\\n      Good evening, how are you ? I'm fine...\n",
       "2        \\n\\n      CAREER PLAN Name : Jean-Philippe BLA...\n",
       "3        \\n\\n      Hi My favortite hobby with my famill...\n",
       "4        \\n\\n      My great job, but... I am a manager ...\n",
       "5        \\n\\n      Here is the story of a friend of min...\n",
       "6        \\n\\n      I Love to travel. I've visited Thail...\n",
       "7        \\n\\n      While I was studying the Law, I had ...\n",
       "8        \\n\\n      Hello, My name's Erwan. I'm in great...\n",
       "9        \\n\\n      John learn that Isabella should to g...\n",
       "10       \\n\\n      To whom it may concern: I am writing...\n",
       "11       \\n\\n      Hello,I'm really sorry to tell you t...\n",
       "12       \\n\\n      My name's Dominique, I am buyer, I w...\n",
       "13       \\n\\n      Today at 6.30 p.m I'm going to a lec...\n",
       "14       \\n\\n      HI,sorry the weather is horrible and...\n",
       "15       \\n\\n      For some aches, home remedies could ...\n",
       "16       \\n\\n      HelloFor my birthday I'd like to do ...\n",
       "17       \\n\\n      Dear Sir or Madam, My name is Adelin...\n",
       "18       \\n\\n      Hi. The online catalog has : -sneake...\n",
       "19       \\n\\n      Dear Mom and Dad, In September, I wi...\n",
       "20       \\n\\n      In Santa Monica today it's going to ...\n",
       "21       \\n\\n      I think the president board prepared...\n",
       "22       \\n\\n      Hi Mom and Dad,Today we are in Santa...\n",
       "23       \\n\\n      Date : Monday 11th Time : 9.30 am Fo...\n",
       "24       \\n\\n      I work in an office. I sit an my des...\n",
       "25       \\n\\n      Name: Mehdy. Age: eight and half. Wo...\n",
       "26       \\n\\n      My name's Brigitte. I'm 64 years old...\n",
       "27       \\n\\n      Dear Mr Gibson,Thanks for your answe...\n",
       "28       \\n\\n      Dear Ms Thomas, There are thirty pen...\n",
       "29       \\n\\n      Hi Mum and Dad,I'm in Santa Monica f...\n",
       "                               ...                        \n",
       "25263     Park City, Utah  (CNN) Former Vice President ...\n",
       "25264    During a press conference on Wednesday,   Dona...\n",
       "25265    On Thursday at 7 p. m. ET,   Donald Trump will...\n",
       "25266    ’  ’ ”   Joe Ricketts, the billionaire founder...\n",
       "25267    GOP frontrunner Donald Trump is responding to ...\n",
       "25268    Sunday on NBC’s “Meet The Press,” actor George...\n",
       "25269    Pennsylvania State Rep. Jamie Santora ( ) is p...\n",
       "25270    Sen. Marco Rubio was asked to define the term ...\n",
       "25271    A North Park University student fabricated a s...\n",
       "25272    ’You don’t have to go to bed early.’ ’Write do...\n",
       "25273    Presumptive Republican nominee Donald Trump re...\n",
       "25274     (CNN) Paddles at the ready! One of the world’...\n",
       "25275    Washington (CNN) House Speaker Paul Ryan’s att...\n",
       "25276     (CNN) Things have been messy between singer C...\n",
       "25277    NEW ORLEANS, Louisiana  —   After the Federal ...\n",
       "25278    Washington (CNN) Newly elected Democratic Nati...\n",
       "25279     (CNN) Justice may be blind, but it’s easy to ...\n",
       "25280    Student protesters sabotaged a Berkeley Colleg...\n",
       "25281    Neighbors of Facebook founder Mark Zuckerberg ...\n",
       "25282    Democratic presidential candidate Hillary Clin...\n",
       "25283    Bill Maher, the host of HBO’s “Real Time,” moc...\n",
       "25284    What first lady Melania Trump and first daught...\n",
       "25285    Hillary Clinton leads Donald Trump by 12 point...\n",
       "25286    ’  ’ ’     Donald Trump on Sunday named Republ...\n",
       "25287    ’’ ’Yahoo is reported to have rejected ”severa...\n",
       "25288    Editor’s Note: Sen. Rand Paul responded to McC...\n",
       "25289    Washington (CNN) The Department of Justice has...\n",
       "25290    ’  ’ ’   Everyone knows people on Wall Street ...\n",
       "25291    ’  ’ ”   Over Michael Phelps’ unparalleled Oly...\n",
       "25292    Republican presidential candidate Sen. Ted Cru...\n",
       "Length: 25293, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on concatène les deux dataFrames\n",
    "df = texts_news['content']\n",
    "df.columns = ['fulltext']\n",
    "X_train = X_train.append(df, ignore_index=True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25293,)\n"
     ]
    }
   ],
   "source": [
    "y_texts_news = [5] * texts_news.shape[0]\n",
    "y_train = np.concatenate((y_train, y_texts_news))\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des représentations matricielles des textes (Word2Vec) et enregistrement dans des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEN7yRfd3vhs"
   },
   "source": [
    "Représentation des données:\n",
    "\n",
    "Word2Vec:\n",
    "- http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "- https://www.tensorflow.org/hub/modules/text\n",
    "- https://www.tensorflow.org/hub/modules/google/Wiki-words-250/1\n",
    "- http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXWUW4Ly3vhs"
   },
   "source": [
    "Télécharger GoogleNews-vectors-negative300.bin à https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9TGc1xQ03vhu"
   },
   "outputs": [],
   "source": [
    "#!pip install -q gensim\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('wordToVec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "__3CgXmg3viG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjcUtpDy3viK"
   },
   "source": [
    "On transforme chaque texte en une matrice avec des mots sous forme de vecteurs de taille 300. Les matrices sont complétées avec des vecteurs nuls afin qu'elles aient toutes la même dimension. Les matrices sont stockées sous forme de matrices creuses (scipy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrée:\n",
    "- X: ensemble de textes\n",
    "\n",
    "Sortie:\n",
    "- texts_matrices: matrices calculées avec Word2Vec\n",
    "- size_texts: taille réelle de chaque matrice (utilisé par tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33132,
     "status": "ok",
     "timestamp": 1526163024016,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "Vz3EwhgE3viM",
    "outputId": "12118199-1404-45c0-d4ba-145124d0f35b"
   },
   "outputs": [],
   "source": [
    "def Word2Vec(X):\n",
    "    texts_matrices = []\n",
    "    total_nb_tokens = 0\n",
    "    total_nb_unknown = 0\n",
    "    avg_nb_unknown = 0\n",
    "    for row in X:\n",
    "        #print(\"===TEXT===\")\n",
    "        #print(row)\n",
    "        tokens = nltk.word_tokenize(row)\n",
    "        text_matrix = []\n",
    "        nb_unknown = 0\n",
    "        for word in tokens:\n",
    "            try:\n",
    "                word_emb = word_vectors.wv[word]\n",
    "                text_matrix.append(word_emb)\n",
    "                #print(\"Known word:\", word)\n",
    "            except:\n",
    "                nb_unknown = nb_unknown+1\n",
    "                #print(\"Unknown word:\", word)\n",
    "        if len(text_matrix)==0:\n",
    "            text_matrix = np.zeros(texts_matrices[0].shape[1]).reshape(1,-1)\n",
    "        texts_matrices.append(np.array(text_matrix))\n",
    "\n",
    "        total_nb_tokens = total_nb_tokens + len(tokens)\n",
    "        total_nb_unknown = total_nb_unknown + nb_unknown\n",
    "    texts_matrices = np.array(texts_matrices)\n",
    "    avg_nb_unknown = total_nb_unknown / total_nb_tokens\n",
    "    print(\"texts_matrices.shape=\", texts_matrices.shape)\n",
    "    print(\"Nombre moyens de mots inconnus (par exemple la ponctuation)=\", avg_nb_unknown)\n",
    "    \n",
    "    nb_words_max = -np.inf\n",
    "    for i in range(texts_matrices.shape[0]):\n",
    "        nb_words = texts_matrices[i].shape[0]\n",
    "        if nb_words > nb_words_max:\n",
    "            nb_words_max = nb_words\n",
    "    print(\"Nombre de lignes de la plus grande matrice=\", nb_words_max)\n",
    "    \n",
    "    size_texts = np.zeros(texts_matrices.shape[0])\n",
    "    new_line = np.zeros((1, texts_matrices[1].shape[1]))\n",
    "    for i in range(texts_matrices.shape[0]):\n",
    "        if i%100==0:\n",
    "            print(\"i=\", i)\n",
    "        size_texts[i] = texts_matrices[i].shape[0]\n",
    "        while texts_matrices[i].shape[0] < nb_words_max:\n",
    "            texts_matrices[i] = np.append(texts_matrices[i], new_line, axis=0)\n",
    "        texts_matrices[i] = scipy.sparse.csr_matrix(texts_matrices[i])\n",
    "        #np.sort(size_texts)[-100:]\n",
    "    \n",
    "    return texts_matrices, size_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts_matrices.shape= (25293,)\n",
      "Nombre moyens de mots inconnus (par exemple la ponctuation)= 0.25293818244972477\n",
      "Nombre de lignes de la plus grande matrice= 418\n",
      "i= 0\n",
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n",
      "i= 6600\n",
      "i= 6700\n",
      "i= 6800\n",
      "i= 6900\n",
      "i= 7000\n",
      "i= 7100\n",
      "i= 7200\n",
      "i= 7300\n",
      "i= 7400\n",
      "i= 7500\n",
      "i= 7600\n",
      "i= 7700\n",
      "i= 7800\n",
      "i= 7900\n",
      "i= 8000\n",
      "i= 8100\n",
      "i= 8200\n",
      "i= 8300\n",
      "i= 8400\n",
      "i= 8500\n",
      "i= 8600\n",
      "i= 8700\n",
      "i= 8800\n",
      "i= 8900\n",
      "i= 9000\n",
      "i= 9100\n",
      "i= 9200\n",
      "i= 9300\n",
      "i= 9400\n",
      "i= 9500\n",
      "i= 9600\n",
      "i= 9700\n",
      "i= 9800\n",
      "i= 9900\n",
      "i= 10000\n",
      "i= 10100\n",
      "i= 10200\n",
      "i= 10300\n",
      "i= 10400\n",
      "i= 10500\n",
      "i= 10600\n",
      "i= 10700\n",
      "i= 10800\n",
      "i= 10900\n",
      "i= 11000\n",
      "i= 11100\n",
      "i= 11200\n",
      "i= 11300\n",
      "i= 11400\n",
      "i= 11500\n",
      "i= 11600\n",
      "i= 11700\n",
      "i= 11800\n",
      "i= 11900\n",
      "i= 12000\n",
      "i= 12100\n",
      "i= 12200\n",
      "i= 12300\n",
      "i= 12400\n",
      "i= 12500\n",
      "i= 12600\n",
      "i= 12700\n",
      "i= 12800\n",
      "i= 12900\n",
      "i= 13000\n",
      "i= 13100\n",
      "i= 13200\n",
      "i= 13300\n",
      "i= 13400\n",
      "i= 13500\n",
      "i= 13600\n",
      "i= 13700\n",
      "i= 13800\n",
      "i= 13900\n",
      "i= 14000\n",
      "i= 14100\n",
      "i= 14200\n",
      "i= 14300\n",
      "i= 14400\n",
      "i= 14500\n",
      "i= 14600\n",
      "i= 14700\n",
      "i= 14800\n",
      "i= 14900\n",
      "i= 15000\n",
      "i= 15100\n",
      "i= 15200\n",
      "i= 15300\n",
      "i= 15400\n",
      "i= 15500\n",
      "i= 15600\n",
      "i= 15700\n",
      "i= 15800\n",
      "i= 15900\n",
      "i= 16000\n",
      "i= 16100\n",
      "i= 16200\n",
      "i= 16300\n",
      "i= 16400\n",
      "i= 16500\n",
      "i= 16600\n",
      "i= 16700\n",
      "i= 16800\n",
      "i= 16900\n",
      "i= 17000\n",
      "i= 17100\n",
      "i= 17200\n",
      "i= 17300\n",
      "i= 17400\n",
      "i= 17500\n",
      "i= 17600\n",
      "i= 17700\n",
      "i= 17800\n",
      "i= 17900\n",
      "i= 18000\n",
      "i= 18100\n",
      "i= 18200\n",
      "i= 18300\n",
      "i= 18400\n",
      "i= 18500\n",
      "i= 18600\n",
      "i= 18700\n",
      "i= 18800\n",
      "i= 18900\n",
      "i= 19000\n",
      "i= 19100\n",
      "i= 19200\n",
      "i= 19300\n",
      "i= 19400\n",
      "i= 19500\n",
      "i= 19600\n",
      "i= 19700\n",
      "i= 19800\n",
      "i= 19900\n",
      "i= 20000\n",
      "i= 20100\n",
      "i= 20200\n",
      "i= 20300\n",
      "i= 20400\n",
      "i= 20500\n",
      "i= 20600\n",
      "i= 20700\n",
      "i= 20800\n",
      "i= 20900\n",
      "i= 21000\n",
      "i= 21100\n",
      "i= 21200\n",
      "i= 21300\n",
      "i= 21400\n",
      "i= 21500\n",
      "i= 21600\n",
      "i= 21700\n",
      "i= 21800\n",
      "i= 21900\n",
      "i= 22000\n",
      "i= 22100\n",
      "i= 22200\n",
      "i= 22300\n",
      "i= 22400\n",
      "i= 22500\n",
      "i= 22600\n",
      "i= 22700\n",
      "i= 22800\n",
      "i= 22900\n",
      "i= 23000\n",
      "i= 23100\n",
      "i= 23200\n",
      "i= 23300\n",
      "i= 23400\n",
      "i= 23500\n",
      "i= 23600\n",
      "i= 23700\n",
      "i= 23800\n",
      "i= 23900\n",
      "i= 24000\n",
      "i= 24100\n",
      "i= 24200\n",
      "i= 24300\n",
      "i= 24400\n",
      "i= 24500\n",
      "i= 24600\n",
      "i= 24700\n",
      "i= 24800\n",
      "i= 24900\n",
      "i= 25000\n",
      "i= 25100\n",
      "i= 25200\n",
      "texts_matrices.shape= (6555,)\n",
      "Nombre moyens de mots inconnus (par exemple la ponctuation)= 0.24157770705185488\n",
      "Nombre de lignes de la plus grande matrice= 351\n",
      "i= 0\n",
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n"
     ]
    }
   ],
   "source": [
    "X_train_matrices, size_texts_train = Word2Vec(X_train)\n",
    "X_val_matrices, size_texts_val = Word2Vec(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BzybUaY_3viW"
   },
   "source": [
    "Sauvegarde des textes sous forme de matrices et sauvegarde du vecteur comptenant la taille initiale des textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wort7kt83viU"
   },
   "outputs": [],
   "source": [
    "def save(array, filename):\n",
    "    print(\"Save in\", filename)\n",
    "    for i in range(array.shape[0]):\n",
    "        if i%100==0 and i > 0:\n",
    "            print(\"i=\", i)\n",
    "        size_label = len(str(array.shape[0]))\n",
    "        label = str(i)\n",
    "        while len(label)<size_label:\n",
    "            label = \"0\"+label\n",
    "        scipy.sparse.save_npz(matrix=array[i], file=filename+\"_\"+label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1010
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 756,
     "status": "error",
     "timestamp": 1526157701254,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "zLaqDk6_3viY",
    "outputId": "6eb613ac-940b-47b3-93bb-d8362710825c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save in ./texts_matrices_with_news/train/matrix\n",
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n",
      "i= 6600\n",
      "i= 6700\n",
      "i= 6800\n",
      "i= 6900\n",
      "i= 7000\n",
      "i= 7100\n",
      "i= 7200\n",
      "i= 7300\n",
      "i= 7400\n",
      "i= 7500\n",
      "i= 7600\n",
      "i= 7700\n",
      "i= 7800\n",
      "i= 7900\n",
      "i= 8000\n",
      "i= 8100\n",
      "i= 8200\n",
      "i= 8300\n",
      "i= 8400\n",
      "i= 8500\n",
      "i= 8600\n",
      "i= 8700\n",
      "i= 8800\n",
      "i= 8900\n",
      "i= 9000\n",
      "i= 9100\n",
      "i= 9200\n",
      "i= 9300\n",
      "i= 9400\n",
      "i= 9500\n",
      "i= 9600\n",
      "i= 9700\n",
      "i= 9800\n",
      "i= 9900\n",
      "i= 10000\n",
      "i= 10100\n",
      "i= 10200\n",
      "i= 10300\n",
      "i= 10400\n",
      "i= 10500\n",
      "i= 10600\n",
      "i= 10700\n",
      "i= 10800\n",
      "i= 10900\n",
      "i= 11000\n",
      "i= 11100\n",
      "i= 11200\n",
      "i= 11300\n",
      "i= 11400\n",
      "i= 11500\n",
      "i= 11600\n",
      "i= 11700\n",
      "i= 11800\n",
      "i= 11900\n",
      "i= 12000\n",
      "i= 12100\n",
      "i= 12200\n",
      "i= 12300\n",
      "i= 12400\n",
      "i= 12500\n",
      "i= 12600\n",
      "i= 12700\n",
      "i= 12800\n",
      "i= 12900\n",
      "i= 13000\n",
      "i= 13100\n",
      "i= 13200\n",
      "i= 13300\n",
      "i= 13400\n",
      "i= 13500\n",
      "i= 13600\n",
      "i= 13700\n",
      "i= 13800\n",
      "i= 13900\n",
      "i= 14000\n",
      "i= 14100\n",
      "i= 14200\n",
      "i= 14300\n",
      "i= 14400\n",
      "i= 14500\n",
      "i= 14600\n",
      "i= 14700\n",
      "i= 14800\n",
      "i= 14900\n",
      "i= 15000\n",
      "i= 15100\n",
      "i= 15200\n",
      "i= 15300\n",
      "i= 15400\n",
      "i= 15500\n",
      "i= 15600\n",
      "i= 15700\n",
      "i= 15800\n",
      "i= 15900\n",
      "i= 16000\n",
      "i= 16100\n",
      "i= 16200\n",
      "i= 16300\n",
      "i= 16400\n",
      "i= 16500\n",
      "i= 16600\n",
      "i= 16700\n",
      "i= 16800\n",
      "i= 16900\n",
      "i= 17000\n",
      "i= 17100\n",
      "i= 17200\n",
      "i= 17300\n",
      "i= 17400\n",
      "i= 17500\n",
      "i= 17600\n",
      "i= 17700\n",
      "i= 17800\n",
      "i= 17900\n",
      "i= 18000\n",
      "i= 18100\n",
      "i= 18200\n",
      "i= 18300\n",
      "i= 18400\n",
      "i= 18500\n",
      "i= 18600\n",
      "i= 18700\n",
      "i= 18800\n",
      "i= 18900\n",
      "i= 19000\n",
      "i= 19100\n",
      "i= 19200\n",
      "i= 19300\n",
      "i= 19400\n",
      "i= 19500\n",
      "i= 19600\n",
      "i= 19700\n",
      "i= 19800\n",
      "i= 19900\n",
      "i= 20000\n",
      "i= 20100\n",
      "i= 20200\n",
      "i= 20300\n",
      "i= 20400\n",
      "i= 20500\n",
      "i= 20600\n",
      "i= 20700\n",
      "i= 20800\n",
      "i= 20900\n",
      "i= 21000\n",
      "i= 21100\n",
      "i= 21200\n",
      "i= 21300\n",
      "i= 21400\n",
      "i= 21500\n",
      "i= 21600\n",
      "i= 21700\n",
      "i= 21800\n",
      "i= 21900\n",
      "i= 22000\n",
      "i= 22100\n",
      "i= 22200\n",
      "i= 22300\n",
      "i= 22400\n",
      "i= 22500\n",
      "i= 22600\n",
      "i= 22700\n",
      "i= 22800\n",
      "i= 22900\n",
      "i= 23000\n",
      "i= 23100\n",
      "i= 23200\n",
      "i= 23300\n",
      "i= 23400\n",
      "i= 23500\n",
      "i= 23600\n",
      "i= 23700\n",
      "i= 23800\n",
      "i= 23900\n",
      "i= 24000\n",
      "i= 24100\n",
      "i= 24200\n",
      "i= 24300\n",
      "i= 24400\n",
      "i= 24500\n",
      "i= 24600\n",
      "i= 24700\n",
      "i= 24800\n",
      "i= 24900\n",
      "i= 25000\n",
      "i= 25100\n",
      "i= 25200\n",
      "Save in ./texts_matrices_with_news/val/matrix\n",
      "i= 100\n",
      "i= 200\n",
      "i= 300\n",
      "i= 400\n",
      "i= 500\n",
      "i= 600\n",
      "i= 700\n",
      "i= 800\n",
      "i= 900\n",
      "i= 1000\n",
      "i= 1100\n",
      "i= 1200\n",
      "i= 1300\n",
      "i= 1400\n",
      "i= 1500\n",
      "i= 1600\n",
      "i= 1700\n",
      "i= 1800\n",
      "i= 1900\n",
      "i= 2000\n",
      "i= 2100\n",
      "i= 2200\n",
      "i= 2300\n",
      "i= 2400\n",
      "i= 2500\n",
      "i= 2600\n",
      "i= 2700\n",
      "i= 2800\n",
      "i= 2900\n",
      "i= 3000\n",
      "i= 3100\n",
      "i= 3200\n",
      "i= 3300\n",
      "i= 3400\n",
      "i= 3500\n",
      "i= 3600\n",
      "i= 3700\n",
      "i= 3800\n",
      "i= 3900\n",
      "i= 4000\n",
      "i= 4100\n",
      "i= 4200\n",
      "i= 4300\n",
      "i= 4400\n",
      "i= 4500\n",
      "i= 4600\n",
      "i= 4700\n",
      "i= 4800\n",
      "i= 4900\n",
      "i= 5000\n",
      "i= 5100\n",
      "i= 5200\n",
      "i= 5300\n",
      "i= 5400\n",
      "i= 5500\n",
      "i= 5600\n",
      "i= 5700\n",
      "i= 5800\n",
      "i= 5900\n",
      "i= 6000\n",
      "i= 6100\n",
      "i= 6200\n",
      "i= 6300\n",
      "i= 6400\n",
      "i= 6500\n"
     ]
    }
   ],
   "source": [
    "directory = \"texts_matrices_with_news\"\n",
    "directory2 = \"size_texts_with_news\"\n",
    "\n",
    "filename = \"./\" + directory + \"/train/matrix\"\n",
    "save(X_train_matrices, filename)\n",
    "\n",
    "filename = \"./\" + directory2 + \"/train\"\n",
    "np.save(filename, size_texts_train, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "filename = \"./\" + directory + \"/val/matrix\"\n",
    "save(X_val_matrices, filename)\n",
    "\n",
    "filename = \"./\" + directory2 + \"/val\"\n",
    "np.save(filename, size_texts_val, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np.array(y_train).reshape(-1,)\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde des y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory3 = \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./\" + directory3 + \"/train\"\n",
    "np.save(filename, y_train, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "filename = \"./\" + directory3 + \"/val\"\n",
    "np.save(filename, y_val, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPw_A2ta3vim"
   },
   "source": [
    "# Chargement des données déjà préparées\n",
    "!!!!!!!!!!! Cette partie ne marche pas !!!!!!!!!!!!! (n'exécuter que la première et dernière cellule pour les imports et la création des ensembles d'entrainement et de validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vZTDQYA73vim"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s_g3WVMx3viq"
   },
   "outputs": [],
   "source": [
    "def load(list_files):\n",
    "    list_files = np.sort(list_files)\n",
    "    res = []\n",
    "    for i in range(list_files.shape[0]):\n",
    "        if i%100==0 and i > 0:\n",
    "            print(\"i=\", i)\n",
    "        res.append(sparse.load_npz(file=list_files[i]))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qSWqAMnK3viy",
    "outputId": "7d429412-52a1-446a-c8e1-373eebb5f18f"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "list_files = np.array(glob.glob(\"./texts_matrices/*.npz\"))\n",
    "texts_matrices = load(list_files)\n",
    "test_dense_load = sparse.csr_matrix.todense(texts_matrices[0])\n",
    "print(test_dense_load)\n",
    "print(test_dense_load.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylCahmqS3vi4"
   },
   "outputs": [],
   "source": [
    "filename = \"./size_texts.npy\"\n",
    "size_texts = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1526163737206,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "goswoI0d3vi8",
    "outputId": "735d896a-4a2d-4141-fa47-229c0fafe172"
   },
   "outputs": [],
   "source": [
    "print(size_texts.shape)\n",
    "print(size_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1526163743600,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "um3Nkted3vjE",
    "outputId": "db34b931-057c-4dae-d286-3eead2894dc3"
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAnoP9BE3vjI"
   },
   "source": [
    "Séparation en deux ensembles: un ensemble d'entrainement et un ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9CbnAP6m3vjI"
   },
   "outputs": [],
   "source": [
    "training_size = 0.7\n",
    "\n",
    "X_train = texts_matrices[0:int(texts_matrices.shape[0]*training_size)]\n",
    "y_train_full = y_train\n",
    "y_train = y_train_full[0:int(texts_matrices.shape[0]*training_size)]\n",
    "size_texts_train = size_texts[0:int(texts_matrices.shape[0]*training_size)]\n",
    "\n",
    "X_val = texts_matrices[int(texts_matrices.shape[0]*training_size):]\n",
    "y_val = y_train_full[int(texts_matrices.shape[0]*training_size):]\n",
    "size_texts_val = size_texts[int(texts_matrices.shape[0]*training_size):]\n",
    "del texts_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWgDYp7H3vjO"
   },
   "source": [
    "# Un premier réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYtAXkKc3vjO"
   },
   "source": [
    "Pour commencer, descente de gradient stochastique avec les 100 premiers textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 516,
     "status": "error",
     "timestamp": 1526164036948,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "T5sAjMKw3vjO",
    "outputId": "65b336ea-5ab9-42d7-99da-79ff24db0775"
   },
   "outputs": [],
   "source": [
    "X_train_100 = X_train[:100]\n",
    "print(X_train_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fozvM51K3vjY"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train.reset_index().iloc[:,1])\n",
    "y_val = np.array(y_val.reset_index().iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1526163760998,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "vRo0WwDT3vjk",
    "outputId": "78ec463a-b53f-4c01-aea2-c13253137032"
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "y_train_100 = y_train[:100]\n",
    "print(y_train_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1526163763718,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "WMJMkq4P3vjo",
    "outputId": "458660fc-87b5-46bc-e791-97c4ed46c5a4"
   },
   "outputs": [],
   "source": [
    "n_steps = X_train[0].shape[0] #taille des textes (rendue fixe)\n",
    "n_inputs = X_train[0].shape[1] #taille des vecteurs représentant chaque mot\n",
    "print(\"Nombre de mots des textes (fixe) =\", n_steps)\n",
    "print(\"Taille vecteur d'un mot =\", n_inputs)\n",
    "n_neurons = 500\n",
    "n_outputs = 6\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 20\n",
    "n_batches_per_epoch = X_train_100.shape[0] // batch_size\n",
    "print(\"Nombre de batchs par epoch =\", n_batches_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1526163770646,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "PCvcfDiq3vjy",
    "outputId": "6bbe3007-96dd-450d-d612-af2aeb6e111d"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "def get_next_batch(texts_matrices, iteration, batch_size):\n",
    "    size_text = texts_matrices[0].shape[0]\n",
    "    size_word = texts_matrices[0].shape[1]\n",
    "    #print(\"(batch_size, size_text, size_word)=\", batch_size, size_text, size_word)\n",
    "    X_batch = np.zeros((batch_size, size_text, size_word)) \n",
    "    temp1 = texts_matrices[iteration*batch_size:(iteration+1)*batch_size]\n",
    "    for i in range(temp1.shape[0]):\n",
    "        X_batch[i] = np.array(sparse.csr_matrix.todense(temp1[i]))\n",
    "    return X_batch\n",
    "#test\n",
    "temp = get_next_batch(X_train, 0, 3)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1526163775148,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "4cgxa_Ae3vj2",
    "outputId": "0c4c52fa-5e2a-4d8c-e899-d6fcaf722e9e"
   },
   "outputs": [],
   "source": [
    "print(X_train_100.shape)\n",
    "print(y_train_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xtX5n8Nz3vj6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_steps, n_inputs], name=\"X\")\n",
    "seq_length = tf.placeholder(tf.int32, [None]) #vecteur avec les nombres de mots dans les textes\n",
    "y = tf.placeholder(tf.int64, shape=[None], name=\"y\")\n",
    "\n",
    "basic_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, sequence_length=seq_length, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(inputs=states, units=n_outputs, name=\"logits\")\n",
    "inference = tf.nn.softmax(logits, name=\"inference\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(\"./summary\", tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58484,
     "status": "ok",
     "timestamp": 1526163847042,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "t0u7TIsl3vj-",
    "outputId": "663af283-1e00-4cb7-dd52-6f667b44eb97"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_batches_per_epoch):\n",
    "            X_batch = get_next_batch(X_train_100, iteration, batch_size)\n",
    "            y_batch = y_train_100[iteration*batch_size:(iteration+1)*batch_size]\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, seq_length: size_texts_train[iteration*batch_size:(iteration+1)*batch_size]})\n",
    "        \n",
    "        #acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        loss_train = loss.eval(feed_dict={X: get_next_batch(X_train_100, 0, 100), y: y_train_100, seq_length: size_texts_train[0:100]})\n",
    "        print(epoch, \"Loss accuracy:\", loss_train)\n",
    "    \n",
    "    save_path = saver.save(sess, \"./natural_language_classifier.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1526163853328,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "FvCjA8Gw3vkE",
    "outputId": "bad83a10-dab7-4b86-e6d6-d860975404be"
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./natural_language_classifier.ckpt\")\n",
    "    res = sess.run(inference, feed_dict={X: get_next_batch(X_train_100, 0, 100), seq_length: size_texts[0:100]})\n",
    "    res = np.argmax(res, axis=1)\n",
    "    print(res.shape)\n",
    "    print(res)\n",
    "print(list(y_train[0:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TW2KuS0Q3vkK"
   },
   "source": [
    "# Mesure de l'erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tzdDmle73vkM"
   },
   "outputs": [],
   "source": [
    "costs = np.array([[0,1,2,3,4,6],[1,0,1,4,5,8],[3,2,0,3,5,8],[10,7,5,0,2,7],[20,16,12,4,0,8],[44,38,32,19,13,0]])\n",
    "names = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gRN_V-_83vkO"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=['A1', 'A2', 'B1', 'B2', 'C1', 'C2'],\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8HR3ZOr73vkS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print_confusion = True\n",
    "def cost(y_pred, y_true, normalize=True):\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    res = (1/y_true.shape[0]) * np.sum(np.multiply(costs, confusion))\n",
    "    \n",
    "    if print_confusion:\n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cnf_matrix, normalize=normalize, title='Normalized confusion matrix')\n",
    "\n",
    "        plt.show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4436,
     "status": "ok",
     "timestamp": 1526163876184,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "wRmEk5lh3vkW",
    "outputId": "83f88620-6124-444d-d00d-701189a96e04"
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./natural_language_classifier.ckpt\")\n",
    "    res = sess.run(inference, feed_dict={X: get_next_batch(X_val[0:1000], 0, 1000), seq_length: size_texts_val[0:1000]})\n",
    "    y_pred = np.argmax(res, axis=1)\n",
    "\n",
    "print(cost(y_pred, y_val[0:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWGx9Oaj3vkY"
   },
   "source": [
    "# Entrainement avec l'ensemble des données d'entrainement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "U-vAlhbB3vkY"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FtWY1cWe3vkc"
   },
   "source": [
    "La cellule ci-dessous implémente la fonction d'erreur de la compétition. Malheureusement argmax n'est pas différentiable donc la fonction n'est pas utilisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YvZU9qS23vke"
   },
   "outputs": [],
   "source": [
    "costs_tf = tf.constant([[0,1,2,3,4,6],[1,0,1,4,5,8],[3,2,0,3,5,8],[10,7,5,0,2,7],[20,16,12,4,0,8],[44,38,32,19,13,0]])\n",
    "\n",
    "def cost_tf(inference, y_true):\n",
    "    y_pred = tf.argmax(inference, axis=1) #pas différentiable...\n",
    "    confusion = tf.confusion_matrix(y_true, y_pred, num_classes=6)\n",
    "    res1 = tf.multiply(costs, confusion)\n",
    "    res2 = tf.reduce_sum(res1)\n",
    "    res3 = tf.divide(res2, tf.shape(y_true)[0])\n",
    "    return res3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSvXyt3I3vke"
   },
   "source": [
    "Principalement un copier-coller du code précédemment mais entrainement avec l'ensemble des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1526161504194,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "mjEinczf3vkg",
    "outputId": "6065d1d7-ba0c-47fe-efdc-8a0ece5536db"
   },
   "outputs": [],
   "source": [
    "n_steps = X_train[0].shape[0] #taille des textes (rendue fixe)\n",
    "n_inputs = X_train[0].shape[1] #taille des vecteurs représentant chaque mot\n",
    "print(\"Nombre de mots des textes (fixe) =\", n_steps)\n",
    "print(\"Taille vecteur d'un mot =\", n_inputs)\n",
    "n_neurons = 500\n",
    "n_outputs = 6\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 200\n",
    "n_batches_per_epoch = X_train.shape[0] // batch_size\n",
    "print(\"Nombre de batchs par epoch =\", n_batches_per_epoch)\n",
    "\n",
    "MAX_CHECKS_WITHOUT_PROGRESS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dZ81rCbi3vkm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_steps, n_inputs], name=\"X\")\n",
    "seq_length = tf.placeholder(tf.int32, [None]) #vecteur avec les nombres de mots dans les textes\n",
    "y = tf.placeholder(tf.int64, shape=[None], name=\"y\")\n",
    "\n",
    "basic_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=tf.nn.elu)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, sequence_length=seq_length, dtype=tf.float32)\n",
    "\n",
    "logits = tf.layers.dense(inputs=states, units=n_outputs, name=\"logits\")\n",
    "inference = tf.nn.softmax(logits, name=\"inference\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    #loss = cost(inference, y)\n",
    "\n",
    "    class_weights = tf.constant([1, 1.48, 2.11, 4.86, 23.14, 227.22])\n",
    "    weights = tf.gather(class_weights, y)\n",
    "    xentropy = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits, weights=weights)\n",
    "    #xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y) #ancienne version (sans poids)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(\"./summary\", tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "mS3gS5P83vkq",
    "outputId": "2bdb3753-0fd9-47db-883b-5acb03600c84"
   },
   "outputs": [],
   "source": [
    "best_loss = np.infty\n",
    "checks_without_progress = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_batches_per_epoch):\n",
    "            if (iteration+1)%10==0:\n",
    "                print(\"Batch n°\", iteration+1)\n",
    "            X_batch = get_next_batch(X_train, iteration, batch_size)\n",
    "            y_batch = y_train[iteration*batch_size:(iteration+1)*batch_size]\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, seq_length: size_texts_train[iteration*batch_size:(iteration+1)*batch_size]})\n",
    "            \n",
    "        #acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        #fonction de coût sur les 5000 premiers textes d'entrainement (pour que ça tienne dans la mémoire vive)\n",
    "        nb_training_examples = 5000\n",
    "        loss_train = loss.eval(feed_dict={X: get_next_batch(X_train[0:nb_training_examples], 0, nb_training_examples), y: y_train[0:nb_training_examples], seq_length: size_texts_train[0:nb_training_examples]})\n",
    "        loss_val = loss.eval(feed_dict={X: get_next_batch(X_val, 0, X_val.shape[0]), y: y_val, seq_length: size_texts_val})\n",
    "        print(epoch, \"Loss training:\", loss_train)\n",
    "        print(epoch, \"Loss validation:\", loss_val)\n",
    "        \n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./natural_language_classifier.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress >= MAX_CHECKS_WITHOUT_PROGRESS:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        #acc_valid_summary = accuracy_summary.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        #summary_writer.add_summary(acc_valid_summary, epoch)\n",
    "\n",
    "    #save_path = saver.save(sess, \"./natural_language_classifier.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dFyuC2Zz3vks"
   },
   "source": [
    "Matrice de confusion + erreur pour l'ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 558,
     "status": "error",
     "timestamp": 1526160265180,
     "user": {
      "displayName": "Nacim Khalis",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111152779592536409858"
     },
     "user_tz": -120
    },
    "id": "MiDrdBJ43vku",
    "outputId": "2ffc196b-b444-4cdd-c960-7eced7c16e63"
   },
   "outputs": [],
   "source": [
    "print_confusion = True\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./natural_language_classifier.ckpt\")\n",
    "    res = sess.run(inference, feed_dict={X: get_next_batch(X_val, 0, X_val.shape[0]), y: y_val, seq_length: size_texts_val})\n",
    "    y_pred = np.argmax(res, axis=1)\n",
    "\n",
    "print(cost(y_pred, y_val))\n",
    "print(cost(y_pred, y_val, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnE7sR163vk0"
   },
   "source": [
    "Nombre d'éléments par classe dans l'ensemble d'entrainement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "T_9xW8Yw3vk2",
    "outputId": "19e461b1-b90e-4c49-b49c-8868c199ea70"
   },
   "outputs": [],
   "source": [
    "nb_texts_per_classe = np.zeros(6)\n",
    "for i in range(y_train.shape[0]):\n",
    "    if (i+1)%100 == 0:\n",
    "        print(i+1)\n",
    "    nb_texts_per_classe[y_train[i]] = nb_texts_per_classe[y_train[i]] + 1\n",
    "print(nb_texts_per_classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOkEjbmO3vk4"
   },
   "source": [
    "Nombre d'éléments par classe dans l'ensemble de validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vum78xNM3vk4",
    "outputId": "faa354c1-3e50-4be5-e76f-542d687ee17b"
   },
   "outputs": [],
   "source": [
    "print(y_val)\n",
    "nb_texts_per_classe = np.zeros(6)\n",
    "for i in range(y_val.shape[0]):\n",
    "    if (i+1)%100 == 0:\n",
    "        print(i+1)\n",
    "    nb_texts_per_classe[y_val[i]] = nb_texts_per_classe[y_val[i]] + 1\n",
    "print(nb_texts_per_classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WctgXoRL3vk6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SqMorIoX3vfW",
    "MXZkKdYg3vfW",
    "DStYdHy53vfq",
    "grbQj7Jq3vgk",
    "gdEtlOon3vgu",
    "SPTEYAHB3vgu",
    "faO1EzDh3vhq",
    "WPw_A2ta3vim",
    "cWgDYp7H3vjO",
    "TW2KuS0Q3vkK"
   ],
   "default_view": {},
   "name": "preparation_donnees_premier_RNN .ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
