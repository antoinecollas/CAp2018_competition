{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Préparation des données avec ELMO à la place de Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/train_cap2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.2\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21848, 60)\n",
      "(5462, 60)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=test_size, random_state=random_state, shuffle=True, stratify=dataset.loc[:,'level1'])\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21848, 59)\n",
      "(21848,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.iloc[:, :-1]\n",
    "y_train = train.iloc[:, -1]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace({\"A1\": 0, \"A2\" : 1, \"B1\" : 2, \"B2\" : 3, \"C1\" : 4, \"C2\" : 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_fulltext = X_train.loc[:, 'fulltext'].iloc[:10]\n",
    "#y_train = y_train[:10]\n",
    "#print(X_train_fulltext)\n",
    "\n",
    "X_train_fulltext = X_train.loc[:, 'fulltext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 0.7\n",
    "\n",
    "X_train = X_train_fulltext[0:int(X_train_fulltext.shape[0]*training_size)]\n",
    "y_train_full = y_train\n",
    "y_train = y_train_full[0:int(X_train_fulltext.shape[0]*training_size)]\n",
    "\n",
    "X_val = X_train_fulltext[int(X_train_fulltext.shape[0]*training_size):]\n",
    "y_val = y_train_full[int(X_train_fulltext.shape[0]*training_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train.reset_index().iloc[:,1])\n",
    "y_val = np.array(y_val.reset_index().iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6555,)\n",
      "(6555,)\n",
      "(15293,)\n",
      "(15293,)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmation avec mode \"eager execution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération d'un module ELMO déjà entrainé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ae25cc1fd345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatestModuleExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_module_for_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_embedding_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_hub/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLatestModuleExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m   \"\"\"Regularly exports registered modules into timestamped directories.\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'estimator'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(X, iteration, batch_size):\n",
    "    X_batch = X[iteration*batch_size:(iteration+1)*batch_size]\n",
    "    return X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_RNN_and_train(X_train, y_train, X_val, y_val, n_steps, n_neurons=500, activation=tf.nn.relu, \n",
    "                               dropout_in=0, dropout_out=0, class_weights=[1, 1, 1, 1, 1, 1], learning_rate=0.001, \n",
    "                               n_epochs=100, batch_size=200, max_checks_without_progress=3):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(dtype=tf.string, shape=[None], name=\"X\")\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y\")\n",
    "    \n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=True)\n",
    "    X_elmo = elmo(X, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "    sequence_length = tf.shape(X_elmo)[1]*tf.ones(tf.shape(X_elmo)[0], dtype=tf.int32)\n",
    "    \n",
    "    dropout_in_placeholder = tf.placeholder_with_default(tf.constant(0.0, dtype=tf.float32), ())\n",
    "    dropout_out_placeholder = tf.placeholder_with_default(tf.constant(0.0, dtype=tf.float32), ())\n",
    "    \n",
    "    basic_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=activation)\n",
    "    basic_cell = tf.contrib.rnn.DropoutWrapper(basic_cell, input_keep_prob=1-dropout_in_placeholder, output_keep_prob=1-dropout_out_placeholder)\n",
    "    outputs, states = tf.nn.dynamic_rnn(basic_cell, X_elmo, sequence_length=sequence_length, dtype=tf.float32)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=states, units=n_outputs, name=\"logits\")\n",
    "    inference = tf.nn.softmax(logits, name=\"inference\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        #loss = cost(inference, y)\n",
    "\n",
    "        class_weights_tf = tf.constant(class_weights)\n",
    "        weights = tf.gather(class_weights_tf, y)\n",
    "        xentropy = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits, weights=weights)\n",
    "        #xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y) #ancienne version (sans poids)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(\"./summary\", tf.get_default_graph())\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    n_batches_per_epoch = X_train.shape[0] // batch_size\n",
    "    print(\"Nombre de batchs par epoch =\", n_batches_per_epoch)\n",
    "    \n",
    "    best_loss = np.infty\n",
    "    checks_without_progress = 0\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            for iteration in range(n_batches_per_epoch):\n",
    "                if (iteration+1)%10==0:\n",
    "                    print(\"Batch n°\", iteration+1)\n",
    "                X_batch = get_next_batch(X_train, iteration, batch_size)\n",
    "                #print(\"X_batch=\", X_batch)\n",
    "                y_batch = y_train[iteration*batch_size:(iteration+1)*batch_size]\n",
    "                #print(\"y_batch=\", y_batch)\n",
    "\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch, dropout_in_placeholder: dropout_in, dropout_out_placeholder: dropout_out})\n",
    "                #print(sess.run(X_elmo, feed_dict={X: X_batch, y: y_batch, dropout_in_placeholder: dropout_in, dropout_out_placeholder: dropout_out}))\n",
    "\n",
    "            #fonction de coût sur les 5000 premiers textes d'entrainement (pour que ça tienne dans la mémoire vive)\n",
    "            nb_training_examples = 5000\n",
    "            if X_train.shape[0] < nb_training_examples:\n",
    "                nb_training_examples = X_train.shape[0]\n",
    "            loss_train = loss.eval(feed_dict={X: get_next_batch(X_train[0:nb_training_examples], 0, nb_training_examples), y: y_train[0:nb_training_examples]})\n",
    "            loss_val = loss.eval(feed_dict={X: get_next_batch(X_val, 0, X_val.shape[0]), y: y_val})\n",
    "            print(epoch, \"Loss training:\", loss_train)\n",
    "            print(epoch, \"Loss validation:\", loss_val)\n",
    "\n",
    "            if loss_val < best_loss:\n",
    "                save_path = saver.save(sess, \"./natural_language_classifier.ckpt\")\n",
    "                best_loss = loss_val\n",
    "                checks_without_progress = 0\n",
    "            else:\n",
    "                checks_without_progress += 1\n",
    "                if checks_without_progress >= MAX_CHECKS_WITHOUT_PROGRESS:\n",
    "                    print(\"Early stopping!\")\n",
    "                    break\n",
    "    return inference, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 450 #taille maximale des textes (rendue fixe)\n",
    "print(\"Nombre maximal de mots par texte (fixe) =\", n_steps)\n",
    "n_neurons = 500\n",
    "activation = tf.nn.relu\n",
    "n_outputs = 6\n",
    "class_weights = [1, 1, 1, 1, 1, 1] #poids de la fonction de coût\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "MAX_CHECKS_WITHOUT_PROGRESS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_graph_RNN_and_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fb1f9381f813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m inference, X = create_graph_RNN_and_train(X_train, y_train, X_val, y_val, n_steps, n_neurons=n_neurons, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                           \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                            \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                           batch_size=batch_size, max_checks_without_progress=MAX_CHECKS_WITHOUT_PROGRESS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_graph_RNN_and_train' is not defined"
     ]
    }
   ],
   "source": [
    "inference, X = create_graph_RNN_and_train(X_train, y_train, X_val, y_val, n_steps, n_neurons=n_neurons, \n",
    "                                          activation=activation, class_weights=class_weights,\n",
    "                                           learning_rate=learning_rate, n_epochs=n_epochs, \n",
    "                                          batch_size=batch_size, max_checks_without_progress=MAX_CHECKS_WITHOUT_PROGRESS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3,)\n",
      "(7,)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "costs = np.array([[0,1,2,3,4,6],[1,0,1,4,5,8],[3,2,0,3,5,8],[10,7,5,0,2,7],[20,16,12,4,0,8],[44,38,32,19,13,0]])\n",
    "names = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=['A1', 'A2', 'B1', 'B2', 'C1', 'C2'],\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print_confusion = True\n",
    "def cost(y_pred, y_true, normalize=True):\n",
    "    confusion = confusion_matrix(y_true, y_pred)\n",
    "    res = (1/y_true.shape[0]) * np.sum(np.multiply(costs, confusion))\n",
    "    \n",
    "    if print_confusion:\n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cnf_matrix, normalize=normalize, title='Normalized confusion matrix')\n",
    "\n",
    "        plt.show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_confusion = True\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./natural_language_classifier.ckpt\")\n",
    "    res = sess.run(inference, feed_dict={X: get_next_batch(X_val, 0, X_val.shape[0])})\n",
    "    y_pred = np.argmax(res, axis=1)\n",
    "\n",
    "print(cost(y_pred, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
